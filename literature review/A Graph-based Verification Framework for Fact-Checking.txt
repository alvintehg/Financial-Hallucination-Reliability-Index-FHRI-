=== Page 1 ===
A Graph-based Verification Framework for Fact-Checking
Yani Huang1, Richong Zhang1,2âˆ—, Zhijie Nie1, Junfan Chen3, Xuefeng Zhang1
1CCSE, School of Computer Science and Engineering, Beihang University, Beijing, China
2Zhongguancun Laboratory, Beijing, China
3School of Software, Beihang University, Beijing, China
{huangyn, zhangxf}@buaa.edu.cn
{zhangrc, niezj, chenjf}@act.buaa.edu.cn
Abstract
Fact-checking plays a crucial role in combating
misinformation. Existing methods using large
language models (LLMs) for claim decompo-
sition face two key limitations: (1) insufficient
decomposition , introducing unnecessary com-
plexity to the verification process, and (2) am-
biguity of mentions , leading to incorrect verifi-
cation results. To address these challenges, we
suggest introducing a claim graph consisting
of triplets to address the insufficient decompo-
sition problem and reduce mention ambiguity
through graph structure. Based on this core
idea, we propose a graph-based framework,
GraphFC, for fact-checking. The framework
features three key components: graph construc-
tion, which builds both claim and evidence
graphs; graph-guided planning , which prior-
itizes the triplet verification order; and graph-
guided checking , which verifies the triples one
by one between claim and evidence graphs.
Extensive experiments show that GraphFC en-
ables fine-grained decomposition while resolv-
ing referential ambiguities through relational
constraints, achieving state-of-the-art perfor-
mance across three datasets.
1 Introduction
Fact-checking plays a crucial role in detecting
misinformation and preventing the spread of ru-
mors. The recent emergence of LLMs, which ex-
hibit powerful semantic understanding capabilities,
has opened up new potential solutions for fact-
checking. Leveraging these LLMs, recent method-
ologies (Pan et al., 2023; Wang and Shu, 2023;
Zhao et al., 2024) have introduced approaches that
decompose claims into textual sub-claims. Such
LLM-driven claim decomposition simplifies the
verification process and allows for more precise
identification of errors within the claim.
Despite their impressive performance, these
decomposition-based methods still face two main
âˆ—Corresponding author.
Claim : The founder  of the school  was the daughter  of Christopher , and his 
sister  Kathleen  was a former  principal  of the school .
Evidence : St Hughâ€™s  College  is a constituent  college  of University  of Oxford . 
It was founded  in 1886  by Elizabeth â€¦ the daughter  of Christopher â€¦ 
Kathleen , Christopher â€™s sister,  was Principal  of Somerville  College â€¦
sub-claim 1 : The founder of the school 
was the daughter of Christopher
sub-claim 2 : Christopher â€™s sister Kathleen 
was a former principal of the school 
T extual sub -claims
 Graph -based sub -claims
Daughter_of  Principal_of
ğ’™ğŸ Founder 
_of
ğ’™ğŸ
Sister 
_of
Christ
opher
Kath
leen
 sub-claim 1      sub-claim 2  â†’ True âˆ§
Figure 1: An illustration demonstrating the differences
between existing textual sub-claims and our graph-based
sub-claims. The example is from the HOVER dataset
(Jiang et al., 2020), and the decomposition results are
from GPT-3.5-Turbo.
challenges. First, without explicit rules, existing
models decompose claims into isolated textual sub-
claims, each maybe containing multiple subjects,
relations, or objects. This decomposition method
leads to insufficient decomposition problem, intro-
ducing unnecessary complexity to the claim ver-
ification process. As in Figure 1, sub-claim 1
comprises two distinct facts: one between â€œ the
founder â€ and â€œ the school â€, while the other be-
tween â€œ the founder â€ and â€œ Christopher â€.
Furthermore, there may be multiple unknown
mentions within the claim text, and the same un-
known mentions could be shared across different
sub-claims. By focusing solely on individual sub-
claims, this decomposition method increases the
ambiguity of mentions , as the shared unknowns are
not contextualized within a unified framework and
neglects the broader context and interconnections,
thereby amplifying the uncertainty associated with
these unknown mentions. As in Figure 1, â€œ the
school â€ in sub-claim 2 presents a referential ambi-
guity. Fact-checking models may incorrectly asso-
ciate â€œ the school â€ with â€œ Somerville College â€
due to an inadequate consideration of the interde-
pendencies between sub-claims.arXiv:2503.07282v1  [cs.CL]  10 Mar 2025

=== Page 2 ===
To overcome the aforementioned limitations, we
suggest converting the claim text into the form of
graph using <subject, relation, object> triplets. The
graph contains two types of entities: the known
entities (the ground entities in the claim) and the
unknown entities (the entities existing as references
or relationships pending resolution). Using this de-
composition method, each triplet can be viewed
as a minimal unit that cannot be further decom-
posed, so the problem of insufficient decomposition
is eliminated. The graph structure also preserves
all contextual information from the original claim,
thus preventing ambiguity of mentions .
Building on such a foundation, we propose
GraphFC, a graph-based fact-checking framework
consisting of three components: (1) graph construc-
tion, besides the claim graph, an evidence graph for
each claim is constructed correspondingly, inspired
by the observation that irrelevant context impairs
verification accuracy from recent research (Guan
et al., 2024). (2) graph-guided planning , priori-
tizes the validation of triplets and determines the
logical sequence for checking each triplet. and (3)
graph-guided checking , which comprises two sub-
tasks: graph match , which verifies the accuracy of
known entity triplets, and graph completion , which
infers incomplete entities for triplets with unknown
entities.
Empirical studies employing closed-source and
open-source LLMs, such as GPT-3.5-Turbo and
Mistral-7B, along with widely-used fact verifi-
cation datasets including HOVER (Jiang et al.,
2020), FEVEROUS (Aly et al., 2021), and Sci-
Fact(Wadden et al., 2020), demonstrate the effec-
tiveness of our proposed framework.
To summarize, the contribution of this study is
three-fold.
â€¢We introduce the graph structure to represent
the complex claims, effectively addressing the
insufficient decomposition problem and reduc-
ing mention ambiguity.
â€¢We propose a graph-based fact-checking
framework (GraphFC) with three components:
graph construction ,graph-guided planning ,
andgraph-guided checking .
â€¢We validate GraphFCâ€™s effectiveness and ra-
tionality through experiments on three public
fact-checking datasets, achieving state-of-the-
art results.2 Background
Fact Checking Given the natural-language claim
C, fact-checking aims to find a model Mfthat
predicts the veracity label Yâˆˆ {True,False}of
the claim Cbased on the provided evidence E,
which can be expressed as
Mf(C, E)â†’Y. (1)
Depending on how Eis accessed, fact-checking
is usually categorized into two types: (1) Gold
Evidence setting, where Eis directly given, and (2)
Open Book setting, where Eneeds to be retrieved
from a specified knowledge source K.
PLM-based Fact Checking In the past few
years, pre-trained language models have demon-
strated strong performance in fact-checking. BERT-
based approaches (Soleimani et al., 2020; Gi et al.,
2021) effectively combine evidence retrieval and
claim verification. Graph-based methods further en-
hance reasoning capabilities by modeling relation-
ships between evidence pieces. GEAR (Zhou et al.,
2019) employs evidence aggregation through graph
networks, while Transformer-XH (Zhao et al.,
2020) introduces extra hop attention for multi-
evidence reasoning.
LLM-based Fact-Checking The emergence of
LLMs has revolutionized fact-checking through
their powerful reasoning capabilities. Chain-of-
Thought (CoT) prompting (Wei et al., 2022) fa-
cilitates decomposing complex verification into
intermediate steps, while self-consistency (Wang
et al., 2022) boosts accuracy via multiple reason-
ing paths. Recent work has focused on developing
specialized decomposition-based prompting strate-
gies for fact verification. HiSS (Zhang and Gao,
2023) proposes a hierarchical approach that de-
composes claims into verifiable sub-claims, while
ProgramFC (Pan et al., 2023) introduces program-
guided reasoning to enhance verification accuracy.
PACAR (Zhao et al., 2024) combines planning with
customized action reasoning. FOLK (Wang and
Shu, 2023) introduces a first-order logic-guided
method for claim decomposition. However, these
decomposition-based methods suffer from insuffi-
cient decomposition and mention ambiguity. Our
work addresses these limitations by introducing
a claim graph built from fine-grained sub-claims
that preserves shared unknown mentions via graph
structure.

=== Page 3 ===
3 Method
3.1 Fact-Checking over Graphs
Task Definition We first give a graph-style defini-
tion for fact-checking here. Concretely, the natural
language claim Cis converted into a directed graph
Gc={(s, r, o ), s, oâˆˆ Ecâˆª Xc, râˆˆ R c}, where
Ecis a known entity set, Xcis the unknown en-
tity set and Rcis the relation set. Specifically, Ec
contains the named or disambiguated real-world
entities, which are determined when decomposing
the claim. In contrast, the entity in Xccan not
be determined according to claim only, as a claim
may contain ambiguous references (e.g., pronouns,
indefinite references) that cannot be immediately
resolved through simple decomposition; instead,
these entities require contextual understanding or
additional inference steps to be determined. Sim-
ilarly, the evidence set Eis organized into an ev-
idence graph Ge={(s, r, o ), s, oâˆˆ Ec, râˆˆ R c},
inspired by the finding of irrelevant evidence im-
pair verification accuracy (Guan et al., 2024). Note
that we define the nodes in Geto contain only the
known entities since evidence usually comes from
knowledge bases, which are written with a clear
presentation of the facts, with few ambiguous refer-
ences. Finally, we give the sufficient and necessary
conditions for a claim to be supported by evidence.
Assertion 1 A claim Gcis supported by evidence
Geif and only if there exists a one-to-one func-
tionÏ•:Ecâˆª Xcâ†’ E esatisfies the following two
conditions at the same time:
p1:âˆ€xâˆˆ Ec, Ï•(x) =x.
p2:âˆ€x, yâˆˆ Ecâˆª Xc,âˆ€râˆˆ R c,
(x, r, y )âˆˆGcâ‡’(Ï•(x), r, Ï•(y))âˆˆGe.
Based on this definition, we summarize the bene-
fits of graph-based verification as follows: (1) is
performed at the ternary level, preventing the prob-
lem of insufficient decomposition; (2) any node in
the claim graph corresponds to a unique node in
the evidence graph, which satisfies all the relation
constraints on the node at the same time, avoiding
the ambiguity of mentions.
GraphFC While Assertion 1 gives a clear idea
of verification, converting it into a practical veri-
fication framework requires more effort. To vali-
date our idea, we propose a fact-checking frame-
work called GraphFC for systematically verify-
ing claims through graphs. As shown in Figure2, GraphFC consists of three primary components:
graph construction ,graph-guided planning , and
graph-guided checking .
3.2 Graph Construction
In graph construction, we transform the claim C
and the corresponding evidence Einto the graph
structures. A specialized graph construction agent
Agcis introduced to complete this complex task.
Claim Graph Construction Claim graph con-
struction aims to transform a natural language
claim Cto a graph Gc. The graph construction
agentAgcis expected to extract all triplets from
claim text to complete this graph construction,
which can be denoted as
Gc={tc
1,Â·Â·Â·, tc
nc}=Agc(C) (2)
where tc
irepresents the i-th triplet extracted from
the claim text and ncrepresents the extracted triplet
number. In practice, the agent Agcis provided with
a task description, an extraction guideline and K
fixed in-context examples for generating triples
that conform to a particular format. In particular,
the unknown entities that appear in the claim are
prompted to be replaced with placeholders like
xito form the triplet. Please refer to Listing 3 to
check the prompt in detail. For example, the triplets
extracted from the claim in Figure 2 are shown as
follows:
tc
1: <x1, Daughter_of , Christopher >
tc
2: <x1, Founder_of , x2>
tc
3: <Kathleen , Sister_of , Christopher >
tc
4: <Kathleen , Principal_of , x2>
Evidence Graph Construction Evidence graph
construction aims to convert the natural language
evidence Eto a graph Ge. The agent Agcin evi-
dence graph construction process identifies entities
in evidence set Ethat are related to the known en-
tities in Ecand extract the related triplets, which is
denoted as
Ge={te
1,Â·Â·Â·, te
ne}=Agc(E,Ec) (3)
where te
irepresents the i-th triplet extracted from
the evidence text and nerepresents the extracted
triplet number. In practice, the agent Agcis pro-
vided with similar prompts and Kin-context ex-
amples as that for the construction of claim graphs.
Please refer to Listing 4 to check the prompt in
detail. Even with constraints on the entity set Ec,

=== Page 4 ===
`
Daughter_of  Principal_ofğ’™ğŸFounder 
_ofâ‘¡ Graph -Guided Planning
â‘¢ Graph -Guided Checkingâ‘  Graph Construction
ğ“ğ’ˆğ’„
St. Hugh
Daughter_of Founded 
_byEliza
beth
Principal
_ofSomer
villeClaim :The founder  of the school  was the daughter  of Christopher , and his sister Kathleen  was a former  principal  of the school .
Evidence Graph ğ‘®ğ’† Claim  Graph ğ‘®ğ’„
ğ’™ğŸ
2ğ‘›ğ‘‘â†ğœŒğ‘¡2ğ‘=ğœŒğ‘¡3ğ‘= 1 3ğ‘Ÿğ‘‘â†ğœŒğ‘¡4ğ‘=2
GraphMatch
Evidence :  Get +  
Triple :  
Question :  Whether  the given 
triple is true or false ?1ğ‘ ğ‘¡â†ğœŒğ‘¡1ğ‘=0
Sister 
_of
Sister _ofğ‘¡1ğ‘
True:Christ
opher
Kath
leenFounder 
_ofEvidence : St Hughâ€™s  College  is a constituent  college  of the University  of Oxford . It was founded  in 1886 by Elizabethâ€¦ 
Elizabeth  was the daughter  of Christopher â€¦ Kathleen , Christopher  â€™s sister,  was Principal  of Somerville  Collegeâ€¦
`GraphCompletion
Evidence :  Get + 
Triple : 
Question : What  is the fuzzy 
entity in the triple ?
:`GraphCompletion
Evidence : Get + 
Triple : 
Question : What  is the fuzzy 
entity in the triple ?
:`GraphMatch
Evidence : Get + 
Triple : 
Question :  Whether  the given 
triple is true or false ?
ğ’™ğŸ ğ’™ğŸFounder 
_of
Prediction : 
RefutesFalse:1ğ‘ ğ‘¡2nd2nd3rd
ğ“ğ’ˆm ğ“ğ’ˆm ğ“gcp ğ“gcpKath
leenChrist
opherSister 
_ofChrist
opherKath
leenDaughter
_of Christ
opherğ’™ğŸ ğ’™ğŸPrincipal
_ofKath
leenğ’™ğŸ ğ’™ğŸ
Sister 
_ofChrist
opherKath
leenDaughter
_of Christ
opherğ’™ğŸPrincipal
_ofKath
leenğ’™ğŸ
Eliza
bethEliza
beth
Somer
villeSomer
villeğ‘¡2ğ‘ğ‘¡3ğ‘ğ‘¡4ğ‘
Æ¸ğ‘¡1ğ‘ Æ¸ğ‘¡2ğ‘ Æ¸ğ‘¡3ğ‘ Æ¸ğ‘¡4ğ‘Figure 2: Overeview of GraphFC. The framework consists of three components: (1) graph construction (&3.2),
where claim graph and corresponding evidence graph are constructed for each claim; (2) graph-guided planning
(&3.3), which determines the verification order based on unknown entity count and plans the sequence of verification
tasks; and (3) graph-guided checking (&3.4), which executes either graph match for verifying the known entity
triples or graph completion for inferring incomplete entity.
there are still far more triples extracted from evi-
dence than claims, but usually, only a few of them
are useful for fact verification. To improve readabil-
ity, Figure 2 only shows the useful triples, whose
output format is as follows:
te
1: <St Hugh 's College , Founded_by , Elizabeth >
te
2: <Elizabeth , Daughter_of , Christopher >
te
3: <Kathleen , Sister_of , Christopher >
te
4: <Kathleen , Principal_of , Somerville >
3.3 Graph-Guided Planning
The triplets {tc
1,Â·Â·Â·, tc
nc}obtained from the claim
graph construction are unordered. If the claim
graph does not contain unknown entities (i.e., Xc=
âˆ…), it is feasible to verify the triples one by one ac-
cording to any order. However, due to the presence
of unknown entities, the order of validation should
be planned because the triple like < x1, Founder_of,
x2> will be difficult to verify before x1andx2are
grounded based on known entities. In GraphFC,
graph-guided planning is denoted as a sorting algo-
rithmSgp, which is expressed as
T=Ë†tc
i,Â·Â·Â·,Ë†tc
nc
=Sgp(Gc) (4)
where Ë†tc
idenotes the i-th triplet to be verified in
the subsequent step of fact-checking. Specifically,
Sgpsorts the triplets of the claim graph by the un-
known entity number in the triplet. For any triplett= (s, p, o ), we use Ï(t)to present its priority for
verification, which can be calculated by
Ï(t) =ï£±
ï£´ï£²
ï£´ï£³2ifsâˆˆ Xcandoâˆˆ Xc
0ifs /âˆˆ Xcando /âˆˆ Xc
1otherwise(5)
where the smaller value of Ï(t)represents the
higher priority for verification. The principle be-
hind prioritizing in this way is summarized here:
firstly, verify the triplet of two known entities only
(Ï= 0); then, ground all unknown entities from
the triplet of a known entity and an unknown entity
(Ï= 1); finally, replace the unknown entities with
the ground truth and verify the triplets of two un-
known entities ( Ï= 2). After obtaining the priority
for each triplet, we sort all triplets in the claim
graph based on their priorities in descending or-
der. The order between two triplets with the same
priority will be organized randomly. Therefore, a
possible ordering for the triples of the claim graph
in Figure 2 is as follows:
Ë†tc
1: <Kathleen , Sister_of , Christopher >
Ë†tc
2: <x1, Daughter_of , Christopher >
Ë†tc
3: <Kathleen , Principal_of , x2>
Ë†tc
4: <x1, Founder_of , x2>
3.4 Graph-Guided Checking
Based on the sorted triple list Tin Equation 4, we
conduct a fact-checking process for each triplet

=== Page 5 ===
in the claim graph Gc. In general, we expect to
generate a binary label Yt={True,False}for each
triplet t, and the fact-verification final label Ywith
respect to the claim Csatisfies:
Y=YË†tc
1âˆ§ Â·Â·Â· âˆ§ YË†tcnc(6)
To achieve this goal, we employ two specialized
components: a graph match agent Agmfor verify-
ing the triple with two known entities and a graph
completion agent Agcpfor verifying the triple with
only one known entity and resolving the other un-
known entity. Note that Agcpwill keep replacing
unknown entities with known entities in the evi-
dence graph. Therefore, as shown in Figure 2, all
triplets originally with two unknown entities will
be updated to have one or two known entities, and
AgmorAgcpcan therefore solve them. We also
give an algorithm-style fact-checking process in
Appendix A.
Graph Match When there is no unknown entity
in the triplet t, we perform the process of graph
match on it. Specifically, The graph match agent
Agmaims to verify whether the triple tis sup-
ported by the evidence and output a binary label
Yt={True,False}. Considering tonly needs
to match with the related triplets in Ge, we filter
unrelated triplets from Gcto improve verification
efficiency. Consequently, the triplets containing
the same known entities in tremain for verification,
which is denoted as G(t)
e. In addition, we empiri-
cally find that adding original evidence text Eas
input will improve fault tolerance (See the anal-
ysis in Section 4.3.1 for details). Therefore, the
verification process of Agmcan be expressed as
Yt=Agm(t, G(t)
e, E) (7)
In practice, Agmis provided with a task description
and an output-format instruction only, without the
in-context examples. Taking tc
1in Figure 2 as an
example, the simplified input and output content
are shown as follows:
# Input ( Eis omitted )
Ë†tc
1: <Kathleen , Sister_of , Christopher >
G(t1)
e:{
te
2: <Elizabeth , Daughter_of , Christopher >
te
3: <Kathleen , Sister_of , Christopher >
te
4: <Kathleen , Principal_of , Somerville >
}
# Output
Ë†tc
1â‰¡te
3â‡’Yt1=TrueGraph Completion When there is only one un-
known entity in the triplet t, the graph completion
agentAgcaims to ground the unknown entity x
in the triple and output (1) an entity eâˆˆ Eeto re-
place xin all triplets of claim graph Gcand (2) a
binary Yt={True,False}. Indicating the success
or failure of unknown entity completion, Ytcan be
simply expressed as Yt= (eÌ¸=None ). Similar to
Agm, we use the filtered related triplets G(t)
eand
the original evidence text Eas the input. Finally,
the completion process of Agcpcan be written as
e, Yt=Agcp(t, G(t)
e, E) (8)
Ifeexists, the unknown entity xof the subsequent
triplets should be replaced by e. Without loss of
generality, suppose that Agcpfind the correspond-
ing known entity eforxin the i-th triplet Ë†tc
i, for
anyi < jâ‰¤nc,j-th triplet Ë†tc
j= (s, r, o )âˆˆ T also
needs to replace xin it with e:
Ë†tc
j=ï£±
ï£´ï£²
ï£´ï£³(e, r, o )ifp=x
(s, r, e )ifo=x
(s, r, o )otherwise(9)
Note that while an unknown entity could theoreti-
cally exist valid mappings to multiple known enti-
ties, in practice Agcptypically finds a unique entity
inGedue to the constraining relationships and
context in Gc, making the determination of ewell-
defined. Agcpis provided with a task description
and an output-format instruction only, without the
in-context examples too. Taking tc
2in Figure 2 as
an example, the simplified input and output content
are shown as follows:
# Input ( Eis omitted )
Ë†tc
2: <x1, Daughter_of , Christopher >
G(t2)
e={
te
2: <Elizabeth , Daughter_of , Christopher >
te
3: <Kathleen , Sister_of , Christopher >
}
# Output
eâ†’Elizabeth â‡’Yt2= (x1! = None) = True
# Update other triplets
Ë†tc
4: <x1, Founder_of , x2>â†<Elizabeth , Founder_of , x2>
Early Stop in Checking The claim requires all
triples to be verified as True for support. In practice,
if any triple validates as False, we terminate the
process early and set the final label Yto False.

=== Page 6 ===
4 Experiment
4.1 Experiment Setup
Datasets We evaluate GraphFC on three widely
used fact-checking datasets. HOVER (Jiang et al.,
2020) comprises claims necessitating multi-hop
reasoning across Wikipedia articles for validation.
We employ its validation set, which is categorized
into three subsets according to reasoning com-
plexity: two-hop, three-hop, and four-hop. For
FEVEROUS (Aly et al., 2021), we use its valida-
tion set and select claims that only require sentence
evidence following (Pan et al., 2023). For SciFact
(Wadden et al., 2020), we employ its validation
set, where claims with complete evidence that ei-
ther support or refute the claim are selected. These
datasets encompass various domains and complex-
ity levels, offering a thorough benchmark for auto-
mated fact-checking systems.
Baselines We evaluate GraphFC against ten
strong baselines in two categories. The first cat-
egory comprises pretrained/fine-tuned models ,
including BERT-FC (Soleimani et al., 2020), which
uses BERT-large for binary classification; LisT5
(Jiang et al., 2021), leveraging T5 with listwise
concatenation; RoBERTa-NLI (Nie et al., 2019a)
andDeBERTaV3-NLI (He et al., 2021), both fine-
tuned on multiple NLI datasets; and MULTIVERS
(Wadden et al., 2021), which employs LongFormer
(Beltagy et al., 2020) for processing long evi-
dence sequences. The second category consists
ofin-context learning models , including Codex
(Chen et al., 2021) and FLAN-T5 (Chung et al.,
2022) with 20-shot learning, ProgramFC (Pan et al.,
2023) combines Codex and FLAN-T5 for generat-
ing reasoning programs. We also implement two
prompt-based approaches: Direct (zero-shot) and
Decomposition (10-shot), which break claims into
multiple textual sub-claims, using GPT-3.5-Turbo.
Although other notable methods like PACAR (Zhao
et al., 2024) exist, they are excluded due to differ-
ences in retrieval techniques and the lack of open-
source code, ensuring a fair comparison. Details
about the baselines are provided in Appendix B
Implementation Details We use
gpt-3.5-turbo-0125 as our main language
model, with Mistral-7B-Instruct-v0.31for
ablation study 4.3.2. Experiments run on a Tesla
1https://huggingface.co/mistralai/Mistral-7B-Instruct-
v0.3V100 SXM2 32GB GPU with Intel(R) Xeon(R)
Silver 4214 CPU. For Graph Construction, we
implement 10-shot learning ( K=10), more chal-
lenging than the 20 examples used by baselines
(Codex, FLAN-T5, ProgramFC). Examples are
randomly sampled from the training set. Graph
completion and matching operate in a zero-shot
mode without demonstrations. In the Gold
Evidence setting (gold), we use provided gold
evidence. In the Open Book setting (open), we
follow ProgramFC (Pan et al., 2023), using BM25
(Robertson et al., 2009) retriever via Pyserini (Lin
et al., 2021) for all methods. The top-5 retrieved
paragraphs serve as evidence.
Evaluation Metric Following (Pan et al., 2023)
and (Wang and Shu, 2023), we employ the macro-
F1 score as the primary metric, which provides a
balanced evaluation across all categories.
4.2 Main Results
GraphFC significantly outperforms state-of-the-art
baselines, as shown in Table 1, highlighting three
key findings that confirm its effectiveness.
GraphFC consistently outperforms existing
methods across all settings. On HOVER, we
achieve accuracy improvements of 3.75-5.73% in
gold settings and 4.08-8.31% in open-book settings
across 2-4 hop claims compared to ProgramFC.
For FEVEROUS, our method outperforming Pro-
gramFC by 1.98% and 5.08% in gold and open
settings, respectively. On SciFact, we obtain 2.47%
and 7.71% gains in gold and open settings, respec-
tively.
GraphFC shows increasing performance gains
with claim complexity. Results on HOVER shows
that performance improvements increase with rea-
soning complexity, from 4.08% for 2-hop to 8.31%
for 4-hop claims in open setting. This validates
the effectiveness of our graph-based approach in
handling complex claims.
GraphFC maintains robust performance in
open setting. The performance gap between open
and gold setting is smaller with GraphFC, showing
a 3.95% gap for 4-hop claims on HOVER com-
pared to ProgramFCâ€™s 6.53%. This improvement
stems from our evidence graph construction that ef-
fectively filters and organizes relevant information
to enhance reasoning.

=== Page 7 ===
ModelHOVER(2-hop) HOVER(3-hop) HOVER(4-hop) FEVEROUS SciFact
gold open gold open gold open gold open gold open
Pretrained/Fine-tuned
BERT-FC 53.40 50.68 50.90 49.86 50.86 48.57 74.71 51.60 - -
LisT5 56.15 52.56 53.76 51.89 51.67 50.46 77.88 54.15 - -
RoBERTa-NLI 74.62 63.62 62.23 53.99 57.98 52.40 88.28 57.80 - -
DeBERTaV3-NLI 77.22 68.72 65.98 60.76 60.49 56.00 91.98 58.81 - -
MULTIVERS 68.86 60.17 59.87 52.55 55.67 51.86 86.03 56.61 77.24 54.17
In-context learning
Codex 70.63 65.07 66.46 56.63 63.49 57.27 89.77 62.58 - -
FLAN-T5 73.69 69.02 65.66 60.23 58.08 55.42 90.81 63.73 - -
ProgramFC 74.10 69.36 66.13 60.63 65.69 59.16 91.77 67.80 84.90 70.63
Direct 73.53 68.85 65.09 53.77 59.03 46.93 88.44 66.41 73.30 60.54
Decompostion 72.67 65.40 66.29 54.65 60.88 54.41 85.79 59.38 81.64 72.92
GraphFC 77.85 73.44 70.35 66.54 71.42 67.47 93.75 72.88 87.37 80.63
Table 1: Comparison of main results (macro-F1 in %) across the HOVER, FEVEROUS, and SciFact datasets in
both open-book and gold evidence settings. The best results are in bold , and the second-best results are underlined .
(a) Component analysis of GraphFC on HOVER in terms of
macro-F1.
(b) Backbone analysis of GraphFC (GPT-3.5 vs Mistral-7B) on
HOVER in terms of macro-F1.
Figure 3: Ablation studies of GraphFC.
4.3 Ablation Study
4.3.1 Component Analysis
To evaluate the effectiveness of key components
in GraphFC, we conduct ablation experiments by
removing or modifying specific components. As
shown in Figure 3a, the variant w/o EG eliminates
theEvidence Graph Construction component, di-
rectly performing fact-checking on raw evidence
texts. only EG exclusively utilizes the constructed
evidence graph without referencing the original
text. w/o GP removes the Graph-Guided Planning
component, leading to independent parallel verifi-
cation of each triple in the claim graph.
Effectiveness of evidence Graph construction.
Removing the evidence graph ( w/o EG ) causes
performance drops at all hop levels on HOVER,
especially a significant decrease at 4 hops claims,
which contain richer knowledge and longer text,
requiring extensive evidence for verification. This
demonstrates the advantage of evidence graphs in
constructing structured evidence that effectivelyfilters out irrelevant context. On the other hand,
using only the evidence graph ( only EG ) leads to
performance loss at all levels, indicating that re-
lying solely on the graph can result in the loss of
valuable information from the evidence text.
Effectiveness of graph-guided planning. Remov-
ing graph-guided planning ( w/o GP ) significantly
decreases overall performance, especially in 4-hop
claims on HOVER which require multi-step rea-
soning, highlighting its crucial role in structuring
multi-step reasoning and ensuring that unknown en-
tities are properly identified in complex verification
tasks.
4.3.2 Backbone Analysis
To investigate the impact of different language
models on model performance, we conducted abla-
tion experiments by replacing GPT-3.5 Turbo with
Mistral-7B across three components: graph con-
struction, matching, and completion agents. The
baseline configuration using GPT-3.5 for all com-
ponents is denoted as GGG , while other configura-

=== Page 8 ===
ExampleDecompositionGraphFC
Claim Label Claim Graph Evidence Graph Fact -Checking
Both Craig Serling and Zhang 
Yimou are film directors by 
profession.supportsğ’„ğŸ:Craig Serling is a film director  â†’true
ğ’„ğŸ:Zhang Yimou is a film director â†’true
Prediction: supports âˆšğ’•ğŸğ’„:<Craig Serling, is, film director>
ğ’•ğŸğ’„:<Zhang Yimou, is, film director>ğ’•ğŸğ’†:<Zhang Yimou, is a, Film director>
ğ’•ğŸğ’†:<Craig Serling, is an, American film director>ğ’•ğŸğ’„â†’true
ğ’•ğŸğ’„â†’true
Prediction: supports âˆš
The professions of the host of the 
2012 documentary Anti -Semitism in 
the 21st Century: The Resurgence 
were journalist and writer.refutesğ’„ğŸ:The host of the documentary is a journalist â†’true
ğ’„ğŸ:The host of the documentary is a writer â†’true
Prediction: supports Ã—ğ’•ğŸğ’„:<ğ‘¥1, host of, 2012 documentary>
ğ’•ğŸğ’„: <ğ‘¥1, is, journalist>
ğ’•ğŸ‘ğ’„:<ğ‘¥1, is, writer>ğ’•ğŸğ’†:<Anti-Semitism in the 21st Century:
The Resurgence, first aired on, on January 8, 2007>
ğ’•ğŸğ’†:<Anti-Semitism in the 21st Century : The Resurgence, 
is hosted by, Judy Woodruff>ğ’•ğŸğ’„â†’None
Prediction: refutes âˆš
The man who produced Arabia 
Mountain (album) co -wrote this 
song . That song was sung by Lily 
Allen.supportsğ’„ğŸ:The man produced Arabia Mountain (album) â†’false
ğ’„ğŸ:The man co -wrote this song â†’true
ğ’„ğŸ‘:This song was sung by Lily Allen â†’true
Prediction: refutes Ã—ğ’•ğŸğ’„:<ğ‘¥1,was sung by, Lilly Allen)
ğ’•ğŸğ’„:<ğ‘¥2, produced, Arabia Mountain>
ğ’•ğŸ‘ğ’„:<ğ‘¥2, co-wrote , ğ‘¥1>ğ’•ğŸğ’†:<Lily Allen, released, Littlest Things>
ğ’•ğŸğ’†:<Arabia Mountain, was produced by, Mark Ronson >
ğ’•ğŸ‘ğ’†:<Littlest Things, was written by, Mark Ronson >ğ’•ğŸğ’„â†’Littlest Things
ğ’•ğŸğ’„â†’Mark Ronson
ğ’•ğŸ‘ğ’„â†’true
Prediction: supports âˆš
The mountains known as the parent 
peak to Momhil Sar is found in 
northern Asia. The highest peak of 
Yengisogat is also found in northern 
Asia.refutesğ’„ğŸ:The mountains known as the parent peak to Momhil Sar 
is found in northern Asia â†’true
ğ’„ğŸ:The highest peak of Yengisogat is also found in northern 
Asiaâ†’true
Prediction: supports Ã—ğ’•ğŸğ’„:<ğ‘¥1,parent peak to, Momhil Sar>
ğ’•ğŸğ’„:<ğ‘¥1,is found in, northern Asia>
ğ’•ğŸ‘ğ’„:<ğ‘¥2,highest peak of, Yengisogat >
ğ’•ğŸ’ğ’„:<ğ‘¥2,is found in, northern Asia>ğ’•ğŸğ’†:<Momhil Sar, situated in, the Hispar Muztagh 
subrange of the Karakoram range>
ğ’•ğŸğ’†:<Trivor , parent peak of, Momhil Sar>
ğ’•ğŸ‘ğ’†:<Yengisogat range, highest peak is, Huangguan Shan>
ğ’•ğŸ’ğ’†:<Yengisogat range, is a subrange of, 
Karakoram mountain range>ğ’•ğŸğ’„â†’Trivor
ğ’•ğŸğ’„â†’false
Prediction: refutes âˆšTable 2: Case study of representative examples from HOVER comparing Decomposition and GraphFC.
tions include MMM (all Mistral-7B), GMM ,GMG ,
andGGM (combinations of both models).
Graph construction component critically de-
pends on advanced LLM capabilities. The full
Mistral-7B configuration ( MMM ) shows signifi-
cant performance degradation, with 2-hop accuracy
dropping from 77.85% to 65.84%. Graph construc-
tion requires strong reasoning abilities to decom-
pose complex claims into fine-grained triples.
Graph match component shows higher model
sensitivity than Completion. The graph matching
configuration ( GMG â€™s) leads to a notable drop in
2-hop accuracy to 75.31%, while the completion
component ( GGM â€™s) remains relatively robust with
accuracy only decreasing to 76.01%. This aligns
with the distribution of reasoning tasks on HOVER,
as shown in Figure 4, where matching operations
dominate verification tasks across all hops. These
findings suggest that while graph construction re-
quires powerful models, other components can uti-
lize lighter models when prioritizing computational
efficiency over maximum accuracy.
Figure 4: Distribution of task proportions for graph
match and graph completion on HOVER
4.4 Case Study
To demonstrate GraphFCâ€™s ability to address the
limitations of existing decomposition-based meth-
ods, we compare it with the baseline Decomposi-tion method using four examples of varying com-
plexity in Table 2. For clarity, only essential triples
from the evidence graph that directly support or
refute the claim are shown. The first example high-
lights the ability of both methods to handle simple
claims with clear entity relationships. The third ex-
ample exposes a major limitation of the Decompo-
sition method: when verifying the sub-claim about
â€œArabia Mountainâ€™s producer," it fails to maintain
contextual relationships between decomposed sub-
claims, resulting in ambiguity around "the man."
In contrast, GraphFC preserves these connections
through its graph structure, explicitly modeling en-
tities and their relationships as triples. Additionally,
graph-guided planning optimizes the verification
order, positioning triples with unknown entities
at both ends for later processing. It demonstrates
that GraphFC improves accuracy by preserving
contextual relationships and ensuring an optimal
verification sequence.
5 Conclusion
In this paper, we proposed GraphFC, a graph-
based fact-checking framework that effectively
addresses two critical challenges in LLM-driven
decomposition-based method: insufficient decom-
position and mention ambiguity. By converting
claims into graph structures, our approach pre-
serves contextual relationships while enabling fine-
grained verification through minimal triplet units.
Experimental results demonstrate GraphFCâ€™s effec-
tiveness across three benchmarks, achieving state-
of-the-art performance with significant improve-
ments in complex reasoning scenarios. Ablation
studies highlight the crucial role of graph construc-
tion and graph-guided planning in handling com-
plex claims. These findings establish GraphFC
as an effective approach for enhancing automated
fact-checking systems.

=== Page 9 ===
Limitations
While GraphFC demonstrates substantial improve-
ments over existing approaches, it exhibits limita-
tions in two aspects.
â€¢Our approach achieves relatively modest gains
for simple claims verification. As shown in
Table 1, the improvement margin on 2-hop
claims in the HOVER dataset (0.63% in gold
setting) is notably smaller compared to 3-hop
and 4-hop claims. This limitation is inherent
in our methodâ€™s design: while GraphFC excels
at handling complex multi-hop reasoning, for
simple claims where conventional methods
already perform well, the sophisticated graph
construction and matching procedures may
introduce unnecessary complexity.
â€¢The graph construction component of our
method relies on the reasoning capabilities
of LLMs. As demonstrated in Figure 3b, re-
placing GPT-3.5 with Mistral-7B in the graph
construction phase leads to a significant de-
cline in performance. This suggests that the
accuracy of decomposing claims into fine-
grained triple representations benefits from
the advanced reasoning capabilities of more
powerful language models. Future work will
focus on developing lighter-weight graph con-
struction techniques and exploring more effi-
cient verification strategies for simple claims
while maintaining the current effectiveness on
complex reasoning tasks.
References
Rami Aly, Zhijiang Guo, Michael Schlichtkrull, James
Thorne, Andreas Vlachos, Christos Christodoulopou-
los, Oana Cocarascu, and Arpit Mittal. 2021. Fever-
ous: Fact extraction and verification over unstruc-
tured and structured information. arXiv preprint
arXiv:2106.05707 .
Iz Beltagy, Matthew E Peters, and Arman Cohan. 2020.
Longformer: The long-document transformer. arXiv
preprint arXiv:2004.05150 .
Samuel R. Bowman, Gabor Angeli, Christopher Potts,
and Christopher D. Manning. 2015. A large anno-
tated corpus for learning natural language inference.
InProceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing (EMNLP) ,
pages 632â€“642, Lisbon, Portugal.Mark Chen, Jerry Tworek, Heewoo Jun, Qiming
Yuan, Henrique Ponde De Oliveira Pinto, Jared Ka-
plan, Harri Edwards, Yuri Burda, Nicholas Joseph,
Greg Brockman, et al. 2021. Evaluating large
language models trained on code. arXiv preprint
arXiv:2107.03374 .
Hyung Won Chung, Le Hou, Shayne Longpre, Barret
Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi
Wang, Mostafa Dehghani, Siddhartha Brahma, et al.
2022. Scaling instruction-finetuned language models.
arXiv preprint arXiv:2210.11416 .
In-Zu Gi, Ting-Yu Fang, and Richard Tzong-Han Tsai.
2021. Verdict inference with claim and retrieved
elements using roberta. In Proceedings of the
Fourth Workshop on Fact Extraction and VERifica-
tion (FEVER) , pages 60â€“65.
Jian Guan, Jesse Dodge, David Wadden, Minlie Huang,
and Hao Peng. 2024. Language models hallucinate,
but may excel at fact verification. In Proceedings of
the 2024 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies (Volume 1: Long
Papers) , pages 1090â€“1111, Mexico City, Mexico. As-
sociation for Computational Linguistics.
Pengcheng He, Jianfeng Gao, and Weizhu Chen. 2021.
Debertav3: Improving deberta using electra-style pre-
training with gradient-disentangled embedding shar-
ing. arXiv preprint arXiv:2111.09543 .
Kelvin Jiang, Ronak Pradeep, and Jimmy Lin. 2021. Ex-
ploring listwise evidence reasoning with t5 for fact
verification. In Proceedings of the 59th Annual Meet-
ing of the Association for Computational Linguistics
and the 11th International Joint Conference on Natu-
ral Language Processing (Volume 2: Short Papers) ,
pages 402â€“410.
Yichen Jiang, Shikha Bordia, Zheng Zhong, Charles
Dognin, Maneesh Singh, and Mohit Bansal. 2020.
Hover: A dataset for many-hop fact extraction and
claim verification. arXiv preprint arXiv:2011.03088 .
Jimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-
Hong Yang, Ronak Pradeep, and Rodrigo Nogueira.
2021. Pyserini: A python toolkit for reproducible
information retrieval research with sparse and dense
representations. In Proceedings of the 44th Inter-
national ACM SIGIR Conference on Research and
Development in Information Retrieval , pages 2356â€“
2362.
Alisa Liu, Swabha Swayamdipta, Noah A. Smith, and
Yejin Choi. 2022. WANLI: Worker and AI collabora-
tion for natural language inference dataset creation.
InFindings of the Association for Computational
Linguistics: EMNLP 2022 , pages 6826â€“6847, Abu
Dhabi, United Arab Emirates.
Yixin Nie, Haonan Chen, and Mohit Bansal. 2019a.
Combining fact extraction and verification with neu-
ral semantic matching networks. In Proceedings of

=== Page 10 ===
the AAAI conference on artificial intelligence , pages
6859â€“6866.
Yixin Nie, Haonan Chen, and Mohit Bansal. 2019b.
Combining fact extraction and verification with neu-
ral semantic matching networks. In Proceedings of
the 33rd AAAI Conference on Artificial Intelligence
(AAAI) , pages 6859â€“6866, Honolulu, Hawaii, USA.
Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal,
Jason Weston, and Douwe Kiela. 2020. Adversarial
NLI: A new benchmark for natural language under-
standing. In Proceedings of the 58th Annual Meet-
ing of the Association for Computational Linguistics
(ACL) , pages 4885â€“4901, Online.
Liangming Pan, Xiaobao Wu, Xinyuan Lu, Anh Tuan
Luu, William Yang Wang, Min-Yen Kan, and
Preslav Nakov. 2023. Fact-checking complex claims
with program-guided reasoning. arXiv preprint
arXiv:2305.12744 .
Alicia Parrish, William Huang, Omar Agha, Soo-Hwan
Lee, Nikita Nangia, Alexia Warstadt, Karmanya Ag-
garwal, Emily Allaway, Tal Linzen, and Samuel R.
Bowman. 2021. Does putting a linguist in the loop
improve NLU data collection? In Findings of the
Association for Computational Linguistics: EMNLP
2021 , pages 4886â€“4901, Punta Cana, Dominican Re-
public.
Stephen Robertson, Hugo Zaragoza, et al. 2009. The
probabilistic relevance framework: Bm25 and be-
yond. Foundations and Trends Â®in Information Re-
trieval , 3(4):333â€“389.
Amir Soleimani, Christof Monz, and Marcel Worring.
2020. Bert for evidence retrieval and claim verifi-
cation. In Advances in Information Retrieval: 42nd
European Conference on IR Research, ECIR 2020,
Lisbon, Portugal, April 14â€“17, 2020, Proceedings,
Part II 42 , pages 359â€“366. Springer.
James Thorne, Andreas Vlachos, Christos
Christodoulopoulos, and Arpit Mittal. 2018.
Fever: a large-scale dataset for fact extraction and
verification. arXiv preprint arXiv:1803.05355 .
David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu
Wang, Madeleine van Zuylen, Arman Cohan, and
Hannaneh Hajishirzi. 2020. Fact or fiction: Verifying
scientific claims. arXiv preprint arXiv:2004.14974 .
David Wadden, Kyle Lo, Lucy Lu Wang, Arman Cohan,
Iz Beltagy, and Hannaneh Hajishirzi. 2021. Mul-
tivers: Improving scientific claim verification with
weak supervision and full-document context. arXiv
preprint arXiv:2112.01640 .
Haoran Wang and Kai Shu. 2023. Explainable
claim verification via knowledge-grounded reason-
ing with large language models. arXiv preprint
arXiv:2310.05253 .Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,
Ed Chi, Sharan Narang, Aakanksha Chowdhery, and
Denny Zhou. 2022. Self-consistency improves chain
of thought reasoning in language models. arXiv
preprint arXiv:2203.11171 .
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,
et al. 2022. Chain-of-thought prompting elicits rea-
soning in large language models. Advances in neural
information processing systems , 35:24824â€“24837.
Adina Williams, Nikita Nangia, and Samuel Bowman.
2018. A broad-coverage challenge corpus for sen-
tence understanding through inference. In Proceed-
ings of the 2018 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies (NAACL-
HLT) , pages 1112â€“1122, New Orleans, Louisiana,
USA.
Xuan Zhang and Wei Gao. 2023. Towards llm-based
fact verification on news claims with a hierarchi-
cal step-by-step prompting method. arXiv preprint
arXiv:2310.00305 .
Chen Zhao, Chenyan Xiong, Corby Rosset, Xia
Song, Paul Bennett, and Saurabh Tiwary. 2020.
Transformer-xh: Multi-evidence reasoning with ex-
tra hop attention. In International Conference on
Learning Representations .
Xiaoyan Zhao, Lingzhi Wang, Zhanghao Wang, Hong
Cheng, Rui Zhang, and Kam-Fai Wong. 2024. Pacar:
Automated fact-checking with planning and cus-
tomized action reasoning using large language mod-
els. In Proceedings of the 2024 Joint International
Conference on Computational Linguistics, Language
Resources and Evaluation (LREC-COLING 2024) ,
pages 12564â€“12573.
Jie Zhou, Xu Han, Cheng Yang, Zhiyuan Liu,
Lifeng Wang, Changcheng Li, and Maosong Sun.
2019. Gear: Graph-based evidence aggregating
and reasoning for fact verification. arXiv preprint
arXiv:1908.01843 .
Appendix
A Graph-Guided Fact-Checking
Here we give an algorithm-style graph-guided fact-
checking process in algorithm 1. Based on the
sorted triple list Tin Equation 4, we conduct a
fact-checking process for each triplet in the claim
graph Gc.
1.If the triple contains only grounded entities,
we apply a graph match agent to verify its
validity against G(t)
e. Under this situation, if
the validation process returns a false, then the
fact-checking function returns a false .

=== Page 11 ===
2.Otherwise, if the triple contains an unknown
entity, we apply a graph completion agent
to find the correct entity and ground it. If
grounding is successful, we update both the
claim graph Gcand evidence graph Ge. If the
function fails to find grounding results, the
fact-checking function returns false .
3.If no false returns during the fact-checking
process, then the fact-checking function re-
turns a true.
Algorithm 1 Graph-Guided Fact-Checking
Require: claim graph Gc, evidence graph Ge, ev-
idence set E, agents Agc,Agm,Agcp, and sorted
triples T
Ensure: fact-checking result Y(True or False)
Yâ†True
foreachtinTdo
(s, p, o )â†t
ifs /âˆˆ Xcando /âˆˆ Xcthen
Ytâ† A gm(t, G(t)
e, E)
ifYt==False then
Yâ†False
break
end if
else
e, Ytâ† A gcp(t, G(t)
e, E)
ifYt==False then
Yâ†False
break
else
Ecâ† E câˆªe{Update Claim Graph}
Geâ†Geâˆª A gc(E,[e]){Update Evi-
dence Graph}
end if
end if
end for
return Y
B Baseline Details
We present detailed implementation for our
baseline models across two categories: Pre-
trained/Fine-tuned Models:
â€¢BERT-FC (Soleimani et al., 2020): Employs
bert-large-uncased (345M parameters) for
binary classification, concatenating claims
and evidence as â€™[CLS] claim [SEP] evidenceâ€™.
Fine-tuned using 20 random examples from
the dataset.â€¢LisT5 (Jiang et al., 2021): Implements
t5-large with listwise concatenation, pro-
cessing all evidence sentences simultaneously
for binary classification (Supports/Refutes).
â€¢RoBERTa-NLI (Nie et al., 2019a):
RoBERTa-large model fine-tuned on
SNLI (Bowman et al., 2015), MNLI (Williams
et al., 2018), FEVER-NLI (Nie et al., 2019b),
ANLI (R1, R2, R3) (Nie et al., 2020)
datasets, with additional fine-tuning using 20
task-specific examples from HOVER/FEVER-
OUS.
â€¢DeBERTaV3-NLI (He et al., 2021):
DeBERTaV3-large model trained on 885,242
NLI pairs from FEVER and other NLI
datasets (MNLI, ANLI, LingNLI (Parrish
et al., 2021), WANLI (Liu et al., 2022)).
â€¢MULTIVERS (Wadden et al., 2021): Im-
plements LongFormer (Beltagy et al., 2020)
architecture to handle extended evidence se-
quences, specifically fine-tuned on FEVER
(Thorne et al., 2018) dataset.
In-context Learning Models:
â€¢Codex (Chen et al., 2021): Utilizes
code-davinci-002 with 20 in-context exam-
ples.
â€¢FLAN-T5 (Chung et al., 2022): Leverages
FLAN-T5-XXL (3B parameters) with 20 in-
context examples, using structured prompts
for claim verification.
â€¢ProgramFC (Pan et al., 2023): Combines
Codex and FLAN-T5 for generating reasoning
programs. For fair comparison, we adopt their
single reasoning chain configuration (N = 1).
â€¢Direct, Decomposition : Implements
gpt-3.5-turbo-0125 using two approaches:
(1) zero-shot prompting (Direct) and (2)
claim decomposition with 10 in-context
examples (Decomposition). The latter ap-
proach first breaks down complex claims into
independently verifiable textual sub-claims,
then applies direct prompting to verify
each sub-claim. The complete prompts are
provided in Appendix C.

=== Page 12 ===
C Prompts
Below, we present the prompt templates used for
the baseline methods (Direct, Decomposition) and
GraphFC. For clarity, we have omitted the in-
context-learning examples.
Listing 1: Direct Prompt
[[ Evidence ]]
Based on the above information , is it true that [[ Claim ]]?
True or false ? The answer is:
Listing 2: Decompostion Prompt
## Task Description :
Break down the given into multiple sub claims that :
- Cannot be further divided into simpler meaningful
statements
- Has a clear truth value ( true or false )
- Contains a single subject and predicate
- Does not contain logical connectives (and , or , if -then ,
etc .)
## Input Format :
A complex claim or statement .
## Output Format :
Each atomic proposition should be presented on a new line ,
separated by blank lines for clarity .
## Examples :
(... more in - context examples here ...)
## Real Data :
Input : [[ Claim ]]
Output :
Listing 3: Claim Graph Construction Prompt
# Knowledge Graph Construction Specification
You are an expert in knowledge graph construction . Your task
is to parse natural language claims into a formal
claim graph representation by following these
specifications :
## 1. Entity Types
- Person : Real individuals
- Location : Places , cities , regions
- Organization : Companies , institutions , groups
- Time : Dates , years , periods
- Number : Numerical values
- Concept : Abstract ideas , categories
- Object : Physical items
- Work : Creative works (books , songs , etc .)
- Event : Occurrences , happenings
- Species : Biological organisms
## 2. Constraint Types
- temporal : Time - related constraints (year , date , period )
- spatial : Location - related constraints (in , at , from )
- condition : Qualifying conditions or attributes
- context : Broader situational context
## 3. Atomic Proposition Rules
### Definition
An atomic proposition must :
- Express a single , indivisible fact
- Cannot be broken down into simpler meaningful statements
- Must preserve all relevant context
- Must maintain temporal and spatial relationships
### Decomposition Guidelines
1. Structural Analysis :
- Split complex sentences at conjunction words (and , but ,
or)
- Separate conditional statements (if/ then ) into distinct
propositions
- Identify dependent clauses and their relationships
- Preserve modifiers and qualifiers with their related
concepts
2. Semantic Preservation :
- Maintain causal relationships
- Preserve temporal order
- Keep spatial relationships intact
- Retain contextual qualifiers## 4. Fuzzy Entity Identification Process
### Entity Reference Types
1. Direct Reference :
- Uses proper name (" John ", " Paris ")
- Specific numerical values
- Well - defined concepts
2. Indirect Reference :
- Uses descriptions (" the teacher ", " that city ")
- Role - based references (" the founder ", " the mother ")
- Attribute - based references (" the tall building ")
3. Contextual Reference :
- Requires information from other statements
- Part of a collective reference
- Implied entities
### Fuzzy Entity Decision Tree
1. Initial Check :
- Is the entity referred to by proper name ? Not fuzzy
- Is the entity a specific number or date ? Not fuzzy
- Is the entity a well - defined concept ? Not fuzzy
2. Context Analysis :
- Does the entity require contextual information ? Fuzzy
- Is the entity part of a group or collection ? Fuzzy
- Is the entity only described by role or attribute ?
Fuzzy
- Is the entity referenced through relationships ? Fuzzy
3. Coreference Resolution :
- Track entities across multiple atomic propositions
- Maintain consistent fuzzy entity IDs ($A$ , $B$ , etc .)
- Document relationships between fuzzy entities
## 5. Output Format
### 1. Entity Definitions
```python
entities = [
{
" name ": str , # Entity identifier
" type ": str , # One of the predefined entity
types
"is fuzzy ": bool # True if entity meets fuzzy
criteria
}
]
```
### 2. Relationship Quadruples with Atomic Propositions
```python
quads = [
{
" atomic proposition ": str , # The original atomic
statement this quad represents
" subject ": str , # Entity name or
identifier
" predicate ": str , # Relationship type
" object ": str , # Entity name , identifier
, or value
" constraint ": { # Optional constraint
" type ": str , # One of the predefined
constraint types
" value ": str # Constraint value
}
}
]
```
## 6. Validation Steps
### 1. Quad and Atomic Proposition Validation
For each quad :
- Verify its atomic proposition cannot be further decomposed
- Check if it captures all relevant context
- Ensure temporal / spatial information is preserved
- Validate the relationship between entities
- Check if all relevant constraints are captured
### 2. Semantic Consistency Check
For the entire graph :
- Verify all quads together preserve the original claim 's
meaning
- Check for logical gaps or inconsistencies
- Validate temporal / causal order is maintained
- Ensure entity coreferences are consistent
## 7. Example
(... more in - context examples here ...)
Now , please parse the following claim into the formal
representation described above :
Claim = [[ Claim ]]
Output =

=== Page 13 ===
Listing 4: Evidence Graph Construction Prompt
## Task :
Extract semantic triples from the given evidence and ensure
every extracted triple is context - independent .
## Input :
- Evidence : [ Full text of the evidence ]
- Entities : [ List of entities mentioned , including entity
name and its type ]
## Output Format :
Extract triples separated by newlines , with each triple in
the format :
`Subject | Predicate | Object `
## Extraction Guidelines :
1. Ensure that either ** Predicate ** and ** Object **, or both
in each triple are from the provided Entity Set .
2. " Identify all relationships " from the Evidence Text that
meet this requirement .
3. Every triple should be context - independent . Use full
forms or expanded phrases for relational references
where necessary .
## Examples
(... more in - context examples here ...)
## Real data
Evidence : [[ Evidence ]]
Entity Set :
[[ Entity Set ]]
Output :
Listing 5: Graph Match Prompt
Evidence :
[[ Evidence ]]
Using the provided evidence , determine whether the given
quadruple is true or false .
Quadruple :
[[ Quadruple ]]
Output ( true / false ):
Listing 6: Graph Completion Prompt
Evidence :
[[ Evidence ]]
Complete the fuzzy entity in the quadruple based on above
evidence . If a suitable entity is found , output its
name ; otherwise , output " none ".
Quadruples :
[[ Quadruples ]]
Output :
