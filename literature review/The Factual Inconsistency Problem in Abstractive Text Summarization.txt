=== Page 1 ===
The Factual Inconsistency Problem in Abstractive Text Summarization: A Survey
Yichong Huang ,Xiachong Feng ,Xiaocheng Feng andBing Qin
Research Center for Social Computing and Information Retrieval
Harbin Institute of Technology, China
fychuang, xiachongfeng, xcfeng, qinb g@ir.hit.edu.cn,
Abstract
Recently, various neural encoder-decoder models
pioneered by Seq2Seq framework have been pro-
posed to achieve the goal of generating more ab-
stractive summaries by learning to map input text
to output text. At a high level, such neural mod-
els can freely generate summaries without any con-
straint on the words or phrases used. Moreover,
their format is closer to human-edited summaries
and output is more readable and ﬂuent. However,
the neural model’s abstraction ability is a double-
edged sword. A commonly observed problem with
the generated summaries is the distortion or fabri-
cation of factual information in the article. This in-
consistency between the original text and the sum-
mary has caused various concerns over its applica-
bility, and the previous evaluation methods of text
summarization are not suitable for this issue. In re-
sponse to the above problems, the current research
direction is predominantly divided into two cate-
gories, one is to design fact-aware evaluation met-
rics to select outputs without factual inconsistency
errors, and the other is to develop new summariza-
tion systems towards factual consistency. In this
survey, we focus on presenting a comprehensive re-
view of these fact-speciﬁc evaluation methods and
text summarization models.
1 Introduction
Text summarization is one of the most important yet challeng-
ing tasks in Natural Language Processing (NLP) ﬁeld. It aims
at condensing a piece of text to a shorter version that contains
the main information from the original document [Mani and
Maybury, 1999; Nallapati et al. , 2016 ].
Text summarization approaches can be divided into two
categories: extractive andabstractive .
Extractive summarization is to ﬁnd out the most salient
sentences from the text by considering the statistical features
and then arranging the extracted sentences to create the sum-
mary. Abstractive summarization, on the other hand, is a
technique in which the summary is generated by generating
novel sentences by either rephrasing or using the new words,
Source Document: The magnitude-4.8 quake struck northof the city of Lucca, officials said. The tremor was felt asfar away as Milan and Florence, Italian media say. Therewere no immediate reports of injuries or damage. Italy isprone to earthquakes. In 2009 almost 300 people died in aquake in L'Aquila in the central Abruzzo region...Factually Consistent Summary: An earthquake has shakenparts of northern Italy, forcing some residents onto thestreets.Factually Inconsistent Summary: A powerful earthquakehas struck central Italy, killing at least seven people andinjuring more than 100.Figure 1: An example of factual inconsistency errors. The facts
supported by the source document are marked in green. Factual in-
consistency errors are marked in red.
instead of simply extracting the important sentences [Gupta,
2019 ].
With the great strides of deep learning, neural-based ab-
stractive summarization models are able to produce ﬂuent and
human-readable summaries [Seeet al. , 2017 ].
However, existing neural abstractive summarization mod-
els are highly prone to generate factual inconsistency errors.
It refers to the phenomenon that the summary sometimes dis-
torts or fabricates the facts in the article. Recent studies show
that up to 30% of the summaries generated by abstractive
models contain such factual inconsistencies [Kryscinski et
al., 2020; Falke et al. , 2019 ]. This brings serious problems
to the credibility and usability of abstractive summarization
systems. Figure 1 demonstrates an example article and ex-
cerpts of generated summaries. As shown, “magnitude-4.8
earthquake” is exaggerated into a “powerful quake,” which
will cause adverse social impacts.
On the other hand, most existing summarization evaluation
tools calculate N-gram overlaps between the generated sum-
mary and the human-written reference summary as the qual-
ities of the generated summary, while neglecting fact-level
consistency between two texts. Zhu et al. [2020 ]point that
the generated summaries are often high in token level metrics
like ROUGE [Lin, 2004 ]but lack factual correctness. For in-
stance, the sentences “I am having vacation in Hawaii.” and “IarXiv:2104.14839v3  [cs.CL]  10 Apr 2023

=== Page 2 ===
 Factual Consistency 
 Metrics
 Unsupervised
 Triple-based Textual-Entailment-based QA-based Others Weakly Supervised
 Sentence-level Entity-level Token-level Meta-Evaluation  onFigure 2: Factual consistency metrics.
am not having vacation in Hawaii.” share nearly all unigrams
and bigrams despite having the opposite meaning.
To address the factual inconsistency issue, a lot of au-
tomatic factual consistency evaluation metrics and meta-
evaluation for these metrics are proposed (§3). Besides, much
effort has been devoted to optimizing factual consistency for
summarization systems (§4). In the past three years, more
than twenty studies on factual consistency of summarization
have been proposed. Considering the large amount of effort
dedicated to resolving the factual inconsistency problem and
the large interest of the NLP community in abstractive sum-
marization, in this work we ﬁrst introduce readers to the ﬁeld
of abstractive summarization. Then we focus on the factual
inconsistency problem by giving a broad overview of fac-
tual consistency evaluation and factual consistency optimiza-
tion methods. Throughout this survey, we outline the lessons
learned from the introduced methods and provide views on
possible future directions.
2 Background
In this section, we ﬁrst introduce readers to abstractive sum-
marization methods to better understand the reasons for gen-
erating factual inconsistency errors. Then we give the deﬁni-
tion of the factual inconsistency error and the corresponding
category.
2.1 Abstractive Summarization methods
Conventional abstractive summarization methods usually ex-
tract some keywords from the source document, and then
reorder and perform linguistically motivated transformations
to these keywords [Zajic et al. , 2004 ]. However, previous
paraphrase-based generation methods are easy to produce in-
ﬂuent sentences [Hahn and Mani, 2000 ].
Nallapati et al. [2016 ]ﬁrst proposed to use an RNN (i.e.
encoder ) to encode the source document into a sequence of
word vectors, and use another RNN (i.e. decoder ) to gen-
erate a sequence of words as the generated summary based
on the word vectors from encoder. The encoder and decoder
could also be implemented by CNN [Narayan et al. , 2018 ]
and Transformer [Vaswani et al. , 2017 ]. The decoder of those
sequence-to-sequence based neural text generation is a condi-
tional language model, which makes generating readable and
ﬂuent text possible [Fanet al. , 2018 ]. However, most summa-
rization systems are trained to maximize the log-likelihood
of the reference summary at the word-level, which does not
necessarily reward models for being faithful [Maynez et al. ,
2020 ].2.2 Factual Inconsistency Error
Factual inconsistency errors, i.e., facts inconsistent with the
source document, could be divided into two categories:
Intrinsic Error: the fact that is contradicted to the source
document, which is also referred to as “intrinsic hallucina-
tion” in Maynez et al. [2020 ]. In Figure 1, the word “central”,
which is contradicted to “north” in the source document, be-
longs to this case.
Extrinsic Error: the fact that is neutral to the source doc-
ument (i.e., the content that is neither supported nor contra-
dicted by the source document), which is also referred to as
“extrinsic hallucination”. As shown in Figure 1, “killing at
least seven people and injuring more than 100”, which is not
reported in the source document, belongs to this case.
It is worth mentioning that, existing factual consistency
optimization methods mainly focus on intrinsic errors, and
these two categories are not distinguished in factual consis-
tency evaluation metrics.
3 Factual Consistency Metrics
We take the stock of factual consistency metrics, and then di-
vide them into two categories: unsupervised and weakly su-
pervised, as shown in Figure 2. Unsupervised metrics use
existing tools to evaluate factual consistency of summaries.
According to tools that unsupervised metrics base on, we fur-
ther divide unsupervised metrics into 4 types: Triple-based,
Textual entailment-based, QA-based and Others. Weakly
supervised metrics need to train on the factual consistency
data, which consists of documents and model-generated sum-
maries and factual consistency scores for each summaries. To
compare factual consistency metrics with each other, Meta-
evaluations for factual consistency rise up. We introduce 2
meta-evaluation works about factual consistency. Besides, we
organize existing metrics into Table 1.
3.1 Unsupervised Metrics
Triple-based
The most intuitive way to evaluating factual consistency is
to count the fact overlap between generated summary and the
source document, as shown in Figure 3. Facts are usually rep-
resented by relation triples ( subject, relation, object ), where
the subject has a relation to the object. To extract triples,
Goodrich et al. [2019 ]ﬁrst try to use OpenIE tool [Banko et
al., 2007 ]. However, OpenIE extracts triples with an unspec-
iﬁed schema instead of a ﬁxed schema. In unspeciﬁc schema
extraction, relation is extracted from the text between subject
and object. In ﬁxed schema extraction, a relation is predicted

=== Page 3 ===
Metric Category Summarization Dataset Code
Goodrich et al. [2019 ] Triple-based Wikipedia
Falke et al. [2019 ] Textual-Entailment-based CNN/DM
Mishra et al. [2020 ] Textual-Entailment-based CNN/DM
QAGS [Wang et al. , 2020 ] QA-based CNN/DM, XSum X
FEQA [Durmus et al. , 2020 ] QA-based CNN/DM, XSum X
FactCC [Kryscinski et al. , 2020 ]Weakly-Supervised-based CNN/DM X
HERMAN [Zhao et al. , 2020 ] Weakly-Supervised-based XSum
Zhou et al. [2020 ] Weakly-Supervised-based XSum
Table 1: List of factual consistency metrics. Code refers whether the code is available. Xlinks to corresponding resource location.
Inception is a science fiction film directed by Nolan and starring Leonardo…Source documentLeonardo directed the action film Inception.Summary
(Inception, starring, Leonardo)(Inception, directed by, Nolan)(Leonardo, directed, Inception)
score = 0.5(Inception, is, science fiction film)Source TriplesSummary Triples(Inception, is, action film)
Figure 3: Triple-based factual consistency metrics.
from a pre-deﬁned relations set, which could be viewed as a
classiﬁcation task. Unspeciﬁc schema extraction makes the
extracted triples hard to compare with each other. As shown
in Example 1, from two sentences expressing the same fact,
we will get different triples that mismatch each other.
Example 1 (Relation Extraction with Unspeciﬁc Schema) .
source document: “Obama was born in Hawaii” )
(Obama, born in, Hawaii)
summary: “Hawaii is the birthplace of Obama” )(Hawaii,
is the birthplace of, Obama).
To resolve this problem, Goodrich et al. [2019 ]change to
use relation extraction tools with ﬁxed schema. Considering
still the two sentences in Example 1, whether extracting from
the source document or the summary, the extracted triples are
(Hawaii, is the birthplace of, Obama) in ﬁxed schema extrac-
tion. This helps extracted triples easier to compare.
Textual-Entailment-based
Following the idea that a factually consistent summary is
semantically entailed by the source document , Falke et
al.[2019 ]propose to use textual entailment prediction tools
to evaluate the factual consistency for a summary. Textual
entailment prediction, also known as Natural Language In-
ference (NLI), aims at detecting whether a text P ( Premise )
could entail another text H ( Hypothesis ). However, out-of-
the-box entailment models do not yet offer the desired per-
formance for factual consistency evaluation in text summa-
rization. One reason is that the domain shift from the NLI
Inception is a science fiction film directed by Nolan and starring Leonardo…Source documentLeonardo directed the science fiction film Inception.Summary
Who directed Inception?What kind of film is Inception?LeonardoScience fictionScience fictionNolanSource  AnswersGenerated  QuestionsSummary  Answers
score = 0.5Figure 4: QA-based factual consistency metrics.
dataset to the summarization dataset. Another one is that NLI
models tend to rely on heuristics such as lexical overlap to
explain the high entailment probability. As a consequence,
existing NLI models generalize poorly in downstream tasks.
To make NLI models more generalizable, Mishra et
al.[2020 ]ﬁrst conjecture that a key difference between the
NLI datasets and downstream tasks concerns the length of
the premise. Speciﬁcally, most existing NLI datasets consider
one or at most a few sentences as the premise. However, most
downstream NLP tasks such as text summarization and ques-
tion answering consider the longer text as the premise, which
requires reasoning over longer text. Reasoning over longer
text needs a multitude of additional abilities like coreference
resolution and abductive reasoning. To bridge this gap, they
next create new long premise NLI datasets out of existing QA
datasets for training a truly generalizable NLI model. After
training on this new NLI dataset, the model gains signiﬁcant
improvement in the factual consistency evaluation task.
QA-based
Inspired by other question answering (QA) based automatic
metrics in text summarization, Wang et al. ; Durmus et
al.[2020; 2020 ]propose QA based factual consistency evalu-
ation metrics QAGS and FEQA separately. These two metrics
are all based on the intuition that if we ask questions about a
summary and its source document, we will receive similar an-
swers if the summary is factually consistent with the source

=== Page 4 ===
document. As illustrated in Figure 4, they are all consist of
three steps: (1) Given a generated summary, a question gener-
ation (QG) model generates a set of questions about the sum-
mary, standard answers of which are named entities and key
phrases in the summary. (2) Then using question answering
(QA) model to answers these questions given the source doc-
ument. (3) A factual consistency score is computed based on
the similarity of corresponding answers. Because evaluating
factual consistency at entity-level, these methods are more in-
terpretable than textual-entailment-based methods. The read-
ing comprehension ability of QG and QA models brings these
methods promising performance in this task. However, these
approaches are computationally expensive.
Other Methods
Besides the above methods specially designed, there are also
several simple but effective methods to evaluate factual con-
sistency, which are usually used as baselines. Durmus et
al.[2020 ]propose that a straightforward metric for factual
consistency is the word overlap or semantic similarity be-
tween the summary sentence and the source document. The
word overlap-based metrics compute ROUGE [Lin, 2004 ],
BLEU [Papineni et al. , 2002 ], between the output summary
sentence and each source sentence. And then taking the aver-
age score or maximum score across all the source sentences.
The semantic similarity-based metric is similar to word
overlap-based methods. Instead of using ROUGE or BLEU,
this method uses BERTScore [Zhang* et al. , 2020a ]. These
two types of methods show a baseline level of effectiveness.
And experiments in Durmus et al. [2020 ]show that word
overlap-based methods work better in lowly abstractive sum-
marization datasets like CNN/DM [Hermann et al. , 2015 ],
semantic similarity-based method works better in highly ab-
stractive summarization datasets like XSum [Narayan et al. ,
2018 ]. Abstractiveness of the summarization dataset means
the extent how abstract the reference summaries are against
the source documents. Extremely, the summarization dataset
is the least abstractive if all the reference summaries of which
are directly extracted from the source document.
3.2 Weakly Supervised Metrics
Weakly supervised metrics design models specially for eval-
uating factual consistency. And these models are trained
on synthetic data that are generated from the summariza-
tion dataset automatically, which side-steps the scarcity of
the training data. According to objects to evaluated, exist-
ing metrics are divided into three categories: sentence-level,
entity-level, and token-level.
Sentence-level
Kryscinski et al. [2020 ]propose FactCC, a model to ver-
ify the factual consistency for a summary sentence given
its source document. FactCC is implemented by ﬁne-tuning
pre-trained language model BERT [Devlin et al. , 2019 ]as
a binary classiﬁer. And they further propose to automati-
cally generate synthetic training data from the summarization
dataset CNN/DM [Hermann et al. , 2015 ]. Training examples
are created by ﬁrst sampling single sentences, later referred
to as claims , from the source documents. Claims then passthrough a set of textual transformations that output novel sen-
tences with pseudo positive or negative labels. The positive
examples are obtained through semantically invariant trans-
formations like paraphrasing. The negative examples are ob-
tained through semantically variant transformations like sen-
tence negation and entity swap. In the test stage, FactCC
takes the source document and a summary sentence as input
and outputs the factual consistency label for this summary
sentence. By simulating different kinds of factual inconsis-
tency errors, this method gains some performance improve-
ment in factual consistency evaluation. But at the same time,
this rule-based dataset construction method brings a perfor-
mance bottleneck. Because it is hard to simulate all types of
factual inconsistency errors.
Entity-level
Zhao et al. [2020 ]propose HERMAN, which focuses on
evaluating factual consistency of quantity entities (e.g. num-
bers, dates, etc). HERMAN bases on sequence labeling ar-
chitecture, in which input is the source document and sum-
mary, the output is a sequence of labels indicating which to-
kens consist of factual inconsistent quantity entities. The syn-
thetic training data for HERMAN is automatically generated
from the summarization dataset XSum [Narayan et al. , 2018 ].
Rather than sampling document sentences as claims , Zhao
et al. [2020 ]use reference summary as claims . And these
claims are directly labeled as positive summaries. The nega-
tive summaries are obtained by replacing the quantity entities
in positive summaries.
Token-level
Zhou et al. [2020 ]propose to evaluate factual consistency on
token-level, which is more ﬁne-grained and more explainable
than sentence-level and entity-level evaluation. This token-
level metric is implemented by ﬁne-tuning pre-trained lan-
guage model. Like Zhao et al. [2020 ], reference summaries
are also directly labeled as positive examples, and the nega-
tive examples are obtained by reconstructing part of reference
summaries. This method shows higher correlations with hu-
man factual consistency evaluation.
These weakly supervised metrics attract much attention
recently. But they still needs a large amount of human-
annotated data (the source documents, model-generated sum-
maries, and the factual consistency label for each summary)
to achieve higher performance. However, such data are ex-
ceedingly expensive to produce in terms of both money and
time. While existing weakly supervised methods automat-
ically generate training data with heuristic, they use either
document sentences or reference summaries to construct pos-
itive and negative examples. Nevertheless, both of them are
different from summaries generated by summarization mod-
els. So although existing model-based methods show effec-
tiveness in the training dataset, when applied in the real fac-
tual consistency evaluation scenario, the effect is very limited.
3.3 Meta Evaluation
To verify the effectiveness of the above factual consistency
metrics, most related works usually report the correlation be-
tween their own metric and human-annotated factual consis-
tency score. However, it is still hard to compare each metric

=== Page 5 ===
 Factual Consistency 
 Optimization
 Others   Fact-Encode-based  Textual-Entailment-based  Post-Editing-basedFigure 5: Factual consistency optimization methods.
by the correlations as the diversity of annotating settings in
different works and the disagreement among different annota-
tor groups. To measure the effectiveness of different kinds of
factual consistency metrics, Gabriel et al. ; Koto et al. [2020;
2020 ]conduct meta-evaluations of factual consistency in
summarization. They evaluate the quality of several factual
consistency metrics by computing the correlation between
scores given by these metrics and scores measured by the
same group of annotators.
Through meta-evaluation, Koto et al. [2020 ]ﬁnd that
the semantic similarity-based method could reach state-
of-the-art performance for factual consistency evaluation
by searching optimal model parameters (i.e. model layers
of pre-trained language model in BERTScore) in highly ab-
stractive summarization dataset XSum [Narayan et al. , 2018 ].
Even so, the correlation with human evaluation is not more
than 0.5. Therefore, factual consistency evaluation is still
an open issue in exploration.
4 Factual Consistency Optimization
In this section, we provide an overview of approaches to
optimizing summarization systems towards factual consis-
tency. As illustrated in Figure 5, we divide existing meth-
ods roughly into 4 classes according to principles that each
method bases on: fact encode-based, textual entailment-
based, post-editing-based, and other methods. Besides, we
organize these methods into Table 2.
4.1 Fact-Encode-based
In the earliest research about factual consistency, most works
mainly focus on intrinsic factual inconsistency errors, i.e.,
the fact that is inconsistent with the source document. In-
trinsic factual inconsistency errors convey wrongly the fact
of the source document, which usually manifests as cross-
combinations of the semantic units in different facts. For ex-
ample, “Jenny likes dancing. Bob likes playing football.” )
“Jenny likes playing football”. It is the root cause for in-
trinsic errors that models misunderstand facts in the source
document.
To help summarization systems understand correctly the
facts, the most intuitive method is to explicitly model the
facts in the source document, to augment the representation
of facts. Following this idea, fact encode-based methods ﬁrst
extract facts in the source document, which are usually repre-
sented by relation triples consisting of (subject; relation; ob-
ject). Then, these methods additionally encode the extracted
facts into summarization models. According to the ways to
encoding facts, these methods are divided into two categories:
sequential encode and graph-based encode.sequential fact encode
Cao et al. [2018 ]introduce FTSum, which consists of two
RNN encoders and one RNN decoder. FTSum concatenates
the facts in the source document into a string which is named
fact description . One encoder encodes the source document
and another encoder encodes the fact description . The de-
coder attends the outputs from these two encoders when gen-
erating the summary. Even though experimental results show
that FTSum reduces signiﬁcantly factual inconsistent errors,
it is hard for FTSum to capture the interactions between enti-
ties in all facts.
graph-based fact encode
To resolve this issue, Zhu et al. ; Huang et al. [2020;
2020 ]propose to model the facts in the source document
with knowledge graphs. FASum (Fact-Aware Summariza-
tion) [Zhu et al. , 2020 ], a transformer-based summariza-
tion model, uses a graph neural network (GNN) to learn
the representation of each node (i.e., entities and relations)
and fuses them into the summarization model. Comparing
with FASum, ASGARD (Abstractive Summarization with
Graph Augmentation and semantic-driven RewarD) Huang
et al. [2020 ]further uses multiple choice cloze reward to drive
the model to acquire semantic understanding over the input.
In addition to enhancing the representation of facts in the
source document, incorporating commonsense knowledge is
also useful to facilitate summarization systems understand-
ing the facts. Therefore, Gunel et al. [2019 ]sample relation
triples from Wikidata to construct a commonsense knowledge
graph. In this knowledge graph, TransE [Bordes et al. , 2013 ],
the popular multi-relational data modeling method, is used to
learn entity embeddings. And the summarization system at-
tends to the embedding of related entities when encoding the
source document. In this way, commonsense knowledge is
incorporated into the summarization systems.
4.2 Textual-Entailment-based
Following the idea that a factual consistent summary is se-
mantically entailed by the source document, [Liet al. ,
2018 ]propose an entailment-aware summarization model,
which aims at incorporating entailment knowledge into the
summarization model. Speciﬁcally, they propose a pair
of entailment-aware encoder and decoder. The entailment-
aware encoder is used to learn simultaneously summary
generation and textual entailment prediction. And the
entailment-aware decoder is implemented by entailment Re-
ward Augmented Maximum Likelihood (RAML) training.
RAML [Norouzi et al. , 2016 ]provides a computationally ef-
ﬁcient approach to optimizing task-speciﬁc reward (loss) di-

=== Page 6 ===
Model Category Summarization Dataset Code
FTSum [Caoet al. , 2018 ] Fact-Encode-based Gigaword
FASum [Zhuet al. , 2020 ] Fact-Encode-based CNN/DM, XSum
ASGARD [Huang et al. , 2020 ] Fact-Encode-based CNN/DM, NYT X
Gunel et al. [2019 ] Fact-Encode-based CNN/DM
Liet al. [2018 ] Textual-Entailment-based Gigaword X
SpanFact [Dong et al. , 2020 ] Post-Editing-based CNN/DM, XSum, Gigaword
Caoet al. [2020 ] Post-Editing-based CNN/DM
Matsumaru et al. [2020 ] Other Gigaword, JAMUL
Mao et al. [2020 ] Other CNN/DM, XSum
Zhang et al. [2020b ] Other Radiology Reports Summarization X
Yuan et al. [2020 ] Other E-commerce Product Summarization X
Table 2: List of factual consistency optimization methods. Xlinks to corresponding resource location.
rectly. In this model, the reward is the entailment score of
generated summary.
4.3 Post-Editing-based
The above two kinds of methods optimize summarization
systems towards factual consistency by modifying model
structures. Different from those methods, post-editing-based
methods enhance factual consistency of the ﬁnal summary
by post-editing the model-generated summaries which are
viewed as draft summaries using fact corrects. Fact cor-
rectors take the source document and draft summary as input
and generates the corrected summary as the ﬁnal summary.
Inspired by the QA span selection task, Dong et al. [2020 ]
propose SpanFact, a suite of two span selection-based fact
correctors, which corrects the entities in the draft summary
in an iterative or auto-regressive manner respectively. Be-
fore performing fact correcting, one or all entities (one in the
iterative manner, all in the auto-regressive manner) will be
masked. Then SpanFact selects spans in the source docu-
ment to replace corresponding mask tokens based on the un-
derstanding of the source document.
To train SpanFact, [Dong et al. , 2020 ]construct the dataset
automatically.
Human evaluation results shown that SpanFact success-
fully corrects about 26% factually inconsistent summaries
and wrongly corrupts less than 1% factually consistent sum-
maries. However, SpanFact is limited to correct entity errors.
Simpler than SpanFact, Cao et al. [2020 ]propose an End-
to-End fact corrector, which can correct more types of errors.
This End-to-End fact corrector is implemented by ﬁne-tuning
pre-trained language model BART [Lewis et al. , 2020 ]with
artiﬁcial data. It takes and corrupted summary as input. The
output is the corrected summary. Even though this method
could correct more factually inconsistent errors than Span-
Fact conceptually, it has not outperform SpanFact in human
evaluation result.
Both of Dong et al. [2020 ]and Cao et al. [2020 ]choose
to construct artiﬁcial training data automatically instead of
using expensive human annotation.
However, the gap between the training stage (which learns
to correct the corrupted reference summaries) and the testing
stage (which aims to correct the model-generated summaries)limits the performance of post-editing-based methods for the
reason that corrupted reference summaries have a different
data distribution with the model-generated summaries, which
is the same as weakly supervised factual consistency metrics
(§3.2).
4.4 Other
Apart from the above methods, there are several simple but
useful methods and domain-speciﬁc methods.
Matsumaru et al. [2020 ]conjecture that one of the rea-
sons why the model sometimes generates factually inconsis-
tent summaries lies in unfaithful document-summary pairs,
which are used for training the model. To mitigate this issue,
they further propose to ﬁlter inconsistent training examples
with a textual entailment classiﬁer.
Mao et al. [2020 ]propose to improve factual consistency
by applying constraints during the inference stage (i.e., beam
search stage). Speciﬁcally, summarization models could end
decoding only when all the constraints are met. And the con-
straints are important entities and keyphrases. Because this
method only works at the inference stage as a plug-and-play
module, it could be integrated into any abstractive summa-
rization model without modifying its internal structure. How-
ever, how much improvement of factual consistency could be
achieved by this method and how to design more useful con-
straints are still questions to explore.
Comparing to relatively open domain summarization, such
as news ﬁeld, optimization approaches towards factual con-
sistency in special ﬁeld are more different for their ﬁeld char-
acters. In the medical ﬁeld, Zhang et al. [2020b ]propose to
optimize the factual consistency of radiology reports summa-
rization. Shah et al. [2021 ]propose to optimize the factual
consistency of health and nutrition summarization.
In e-commerce ﬁeld, Yuan et al. [2020 ]propose to opti-
mize the factual consistency of e-commerce product summa-
rization.
5 Conclusion and Future Directions
In this paper, we ﬁrst introduce the factual inconsistency
problem in abstractive summarization. Then we provide an
overview of approaches to evaluating and improving the fac-
tual consistency of summarization systems. Considering the

=== Page 7 ===
landscape that we paint in this paper, we foresee the following
directions:
1.Optimization for Extrinsic Errors. The existing fac-
tual consistency optimizations methods mainly focus on
intrinsic errors, while ignoring extrinsic errors. We ar-
gue that the main reason for the extrinsic factual incon-
sistency errors is that the current maximum likelihood
estimation training strategy cannot explicitly model the
hard constraints between the document and the summary
(e.g., the entities and quotations must appear in the docu-
ment). How to model these constraints into the summary
generation process is a problem worth exploring. And
reinforcement learning may be a feasible way to achieve
this goal.
2.Paragraph-level Metrics. Most evaluation works fo-
cus on calculating sentence-level factual consistency
without considering the relationship between sentences.
Paragraph-level evaluation is more challenging and
valuable.
3.Factual Consistency in other Conditional Text Gen-
eration. Besides the standard text summarization task,
other conditional text generation tasks such as image
captioning and visual storytelling also suffer factual in-
consistency errors and cross-modal factual consistency
is more challenging than single-text.
The above-mentioned research directions are by no means ex-
haustive and are to be considered as guidelines for researchers
wishing to address the factual inconsistency problem in ab-
stractive summarization.
6 Acknowledgements
Xiaocheng Feng is the corresponding author of this work.
We thank the anonymous reviewers for their insightful com-
ments. This work was supported by the National Key
R&D Program of China via grant 2020AAA0106502, Na-
tional Natural Science Foundation of China (NSFC) via grant
62276078 and Natural Science Foundation of Heilongjiang
via grant YQ2019F008.
References
[Banko et al. , 2007 ]Michele Banko, Michael J. Cafarella,
Stephen Soderland, Matt Broadhead, and Oren Etzioni.
Open information extraction from the web. In Proceed-
ings of the 20th International Joint Conference on Artiﬁcal
Intelligence , IJCAI’07, page 2670–2676, San Francisco,
CA, USA, 2007. Morgan Kaufmann Publishers Inc.
[Bordes et al. , 2013 ]Antoine Bordes, Nicolas Usunier,
Alberto Garcia-Dur ´an, Jason Weston, and Oksana
Yakhnenko. Translating embeddings for modeling multi-
relational data. In Proceedings of the 26th International
Conference on Neural Information Processing Systems
- Volume 2 , NIPS’13, page 2787–2795, Red Hook, NY ,
USA, 2013. Curran Associates Inc.
[Caoet al. , 2018 ]Ziqiang Cao, Furu Wei, Wenjie Li, and Su-
jian Li. Faithful to the original: Fact aware neural ab-
stractive summarization. In Proceedings of the Thirty-Second AAAI Conference on Artiﬁcial Intelligence, (AAAI-
18), the 30th innovative Applications of Artiﬁcial Intel-
ligence (IAAI-18), and the 8th AAAI Symposium on Ed-
ucational Advances in Artiﬁcial Intelligence (EAAI-18),
New Orleans, Louisiana, USA, February 2-7, 2018 , pages
4784–4791, 2018.
[Caoet al. , 2020 ]Meng Cao, Yue Dong, Jiapeng Wu, and
Jackie Chi Kit Cheung. Factual error correction for ab-
stractive summarization models. In Proceedings of the
2020 Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP) , pages 6251–6258, Online,
November 2020. Association for Computational Linguis-
tics.
[Devlin et al. , 2019 ]Jacob Devlin, Ming-Wei Chang, Ken-
ton Lee, and Kristina Toutanova. BERT: Pre-training of
deep bidirectional transformers for language understand-
ing. In Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computational
Linguistics: Human Language Technologies, Volume 1
(Long and Short Papers) , pages 4171–4186, Minneapo-
lis, Minnesota, June 2019. Association for Computational
Linguistics.
[Dong et al. , 2020 ]Yue Dong, Shuohang Wang, Zhe Gan,
Yu Cheng, Jackie Chi Kit Cheung, and Jingjing Liu. Multi-
fact correction in abstractive text summarization. In Pro-
ceedings of the 2020 Conference on Empirical Methods
in Natural Language Processing (EMNLP) , pages 9320–
9331, Online, November 2020. Association for Computa-
tional Linguistics.
[Durmus et al. , 2020 ]Esin Durmus, He He, and Mona Diab.
FEQA: A question answering evaluation framework for
faithfulness assessment in abstractive summarization. In
Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics , pages 5055–5070, Online,
July 2020. Association for Computational Linguistics.
[Falke et al. , 2019 ]Tobias Falke, Leonardo F. R. Ribeiro,
Prasetya Ajie Utama, Ido Dagan, and Iryna Gurevych.
Ranking generated summaries by correctness: An inter-
esting but challenging application for natural language in-
ference. In Proceedings of the 57th Annual Meeting of the
Association for Computational Linguistics , pages 2214–
2220, Florence, Italy, July 2019. Association for Compu-
tational Linguistics.
[Fanet al. , 2018 ]Angela Fan, Mike Lewis, and Yann
Dauphin. Hierarchical neural story generation. In Pro-
ceedings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers) ,
July 2018.
[Gabriel et al. , 2020 ]Saadia Gabriel, Asli Celikyilmaz,
Rahul Jha, Yejin Choi, and Jianfeng Gao. Go ﬁgure! a
meta evaluation of factuality in summarization, 2020.
[Goodrich et al. , 2019 ]Ben Goodrich, Vinay Rao, Moham-
mad Saleh, and Peter J. Liu. Assessing the factual ac-
curacy of generated text. Proceedings of the 25th ACM
SIGKDD International Conference on Knowledge Discov-
ery and Data Mining , 2019.

=== Page 8 ===
[Gunel et al. , 2019 ]Beliz Gunel, Chenguang Zhu, Michael
Zeng, and Xuedong Huang. Mind the facts: Knowledge-
boosted coherent abstractive text summarization. In
NeurIPS 2019, Knowledge Representation and Reasoning
Meets Machine Learning(KR2ML) Workshop , December
2019.
[Gupta, 2019 ]Som Gupta. Abstractive summarization: An
overview of the state of the art. Expert Systems with Ap-
plications , 121:49–65, 2019.
[Hahn and Mani, 2000 ]U. Hahn and I. Mani. The challenges
of automatic summarization. Computer , 2000.
[Hermann et al. , 2015 ]Karl Moritz Hermann, Tomas Ko-
cisky, Edward Grefenstette, Lasse Espeholt, Will Kay,
Mustafa Suleyman, and Phil Blunsom. Teaching machines
to read and comprehend. NIPS , 2015.
[Huang et al. , 2020 ]Luyang Huang, Lingfei Wu, and
Lu Wang. Knowledge graph-augmented abstractive sum-
marization with semantic-driven cloze reward. In Pro-
ceedings of the 58th Annual Meeting of the Association
for Computational Linguistics , pages 5094–5107, Online,
July 2020. Association for Computational Linguistics.
[Koto et al. , 2020 ]Fajri Koto, Jey Han Lau, and Timothy
Baldwin. Ffci: A framework for interpretable automatic
evaluation of summarization, 2020.
[Kryscinski et al. , 2020 ]Wojciech Kryscinski, Bryan Mc-
Cann, Caiming Xiong, and Richard Socher. Evaluat-
ing the factual consistency of abstractive text summariza-
tion. In Proceedings of the 2020 Conference on Empiri-
cal Methods in Natural Language Processing (EMNLP) ,
pages 9332–9346, Online, November 2020. Association
for Computational Linguistics.
[Lewis et al. , 2020 ]Mike Lewis, Yinhan Liu, Naman Goyal,
Marjan Ghazvininejad, Abdelrahman Mohamed, Omer
Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART:
Denoising sequence-to-sequence pre-training for natural
language generation, translation, and comprehension. In
Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics , pages 7871–7880, Online,
July 2020. Association for Computational Linguistics.
[Liet al. , 2018 ]Haoran Li, Junnan Zhu, Jiajun Zhang, and
Chengqing Zong. Ensure the correctness of the sum-
mary: Incorporate entailment knowledge into abstractive
sentence summarization. In Proceedings of the 27th Inter-
national Conference on Computational Linguistics , pages
1430–1441, Santa Fe, New Mexico, USA, August 2018.
Association for Computational Linguistics.
[Lin, 2004 ]Chin-Yew Lin. ROUGE: A package for auto-
matic evaluation of summaries. In Text Summarization
Branches Out , pages 74–81, Barcelona, Spain, July 2004.
Association for Computational Linguistics.
[Mani and Maybury, 1999 ]Inderjeet Mani and T. Mark
Maybury. Advances in automatic text summarization. Ad-
vances in Automatic Text Summarization , 1999.
[Mao et al. , 2020 ]Yuning Mao, Xiang Ren, Heng Ji, and Ji-
awei Han. Constrained abstractive summarization: Pre-serving factual consistency with constrained generation,
2020.
[Matsumaru et al. , 2020 ]Kazuki Matsumaru, Sho Takase,
and Naoaki Okazaki. Improving truthfulness of headline
generation. In Proceedings of the 58th Annual Meeting
of the Association for Computational Linguistics , pages
1335–1346, Online, July 2020. Association for Compu-
tational Linguistics.
[Maynez et al. , 2020 ]Joshua Maynez, Shashi Narayan,
Bernd Bohnet, and Ryan McDonald. On faithfulness and
factuality in abstractive summarization. In Proceedings of
the 58th Annual Meeting of the Association for Computa-
tional Linguistics , pages 1906–1919, Online, July 2020.
Association for Computational Linguistics.
[Mishra et al. , 2020 ]Anshuman Mishra, Dhruvesh Patel,
Aparna Vijayakumar, Xiang Li, Pavan Kapanipathi, and
Kartik Talamadupula. Looking beyond sentence-level
natural language inference for downstream tasks. arXiv
preprint arXiv:2009.09099 , 2020.
[Nallapati et al. , 2016 ]Ramesh Nallapati, Bowen Zhou,
C. D. Santos, C ¸ aglar G ¨ulc ¸ehre, and Bing Xiang. Abstrac-
tive text summarization using sequence-to-sequence rnns
and beyond. In CoNLL , 2016.
[Narayan et al. , 2018 ]Shashi Narayan, Shay B. Cohen, and
Mirella Lapata. Don’t give me the details, just the sum-
mary! topic-aware convolutional neural networks for ex-
treme summarization. In Proceedings of the 2018 Con-
ference on Empirical Methods in Natural Language Pro-
cessing , pages 1797–1807, Brussels, Belgium, October-
November 2018. Association for Computational Linguis-
tics.
[Norouzi et al. , 2016 ]Mohammad Norouzi, Samy Bengio,
Navdeep Jaitly, Mike Schuster, Yonghui Wu, Dale Schu-
urmans, et al. Reward augmented maximum likelihood for
neural structured prediction. Advances In Neural Informa-
tion Processing Systems , 29:1723–1731, 2016.
[Papineni et al. , 2002 ]Kishore Papineni, Salim Roukos,
Todd Ward, and Wei-Jing Zhu. Bleu: a method for au-
tomatic evaluation of machine translation. In ACL, pages
311–318, 2002.
[Seeet al. , 2017 ]Abigail See, Peter J. Liu, and Christo-
pher D. Manning. Get to the point: Summarization with
pointer-generator networks. In Proceedings of the 55th
Annual Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers) , pages 1073–1083, Van-
couver, Canada, July 2017. Association for Computational
Linguistics.
[Shah et al. , 2021 ]Darsh J Shah, Lili Yu, Tao Lei, and
Regina Barzilay. Nutri-bullets: Summarizing health stud-
ies by composing segments, 2021.
[Vaswani et al. , 2017 ]Ashish Vaswani, Noam Shazeer, Niki
Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Łukasz Kaiser, and Illia Polosukhin. Attention is all you
need. In Advances in neural information processing sys-
tems, pages 5998–6008, 2017.

=== Page 9 ===
[Wang et al. , 2020 ]Alex Wang, Kyunghyun Cho, and Mike
Lewis. Asking and answering questions to evaluate the
factual consistency of summaries. In Proceedings of the
58th Annual Meeting of the Association for Computational
Linguistics , pages 5008–5020, Online, July 2020. Associ-
ation for Computational Linguistics.
[Yuan et al. , 2020 ]Peng Yuan, Haoran Li, Song Xu,
Youzheng Wu, Xiaodong He, and Bowen Zhou. On
the faithfulness for E-commerce product summarization.
InProceedings of the 28th International Conference on
Computational Linguistics , pages 5712–5717, Barcelona,
Spain (Online), December 2020. International Committee
on Computational Linguistics.
[Zajic et al. , 2004 ]David Zajic, Bonnie J Dorr, and
R. Schwartz. Bbn/umd at duc-2004: Topiary. HLT-
NAACL , 2004.
[Zhang* et al. , 2020a ]Tianyi Zhang*, Varsha Kishore*, Fe-
lix Wu*, Kilian Q. Weinberger, and Yoav Artzi. Bertscore:
Evaluating text generation with bert. In International Con-
ference on Learning Representations , 2020.
[Zhang et al. , 2020b ]Yuhao Zhang, Derek Merck, Emily
Tsai, Christopher D. Manning, and Curtis Langlotz. Op-
timizing the factual correctness of a summary: A study of
summarizing radiology reports. In Proceedings of the 58th
Annual Meeting of the Association for Computational Lin-
guistics , pages 5108–5120, Online, July 2020. Association
for Computational Linguistics.
[Zhao et al. , 2020 ]Zheng Zhao, Shay B. Cohen, and Bonnie
Webber. Reducing quantity hallucinations in abstractive
summarization. In Findings of the Association for Com-
putational Linguistics: EMNLP 2020 , pages 2237–2249,
Online, November 2020. Association for Computational
Linguistics.
[Zhou et al. , 2020 ]Chunting Zhou, Jiatao Gu, Mona Diab,
Paco Guzman, Luke Zettlemoyer, and Marjan Ghazvinine-
jad. Detecting hallucinated content in conditional neural
sequence generation. arXiv preprint arXiv:2011.02593 ,
2020.
[Zhuet al. , 2020 ]Chenguang Zhu, William Hinthorn,
Ruochen Xu, Qingkai Zeng, Michael Zeng, Xuedong
Huang, and Meng Jiang. Boosting factual correctness of
abstractive summarization with knowledge graph, 2020.
