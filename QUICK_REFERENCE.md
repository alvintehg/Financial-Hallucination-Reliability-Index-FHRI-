# FHRI Tightening - Quick Reference Card

## ðŸ“¦ What You Got

### **4 New Python Modules** (Ready to Use)
```
src/numeric_validators.py       # Numeric tolerance validation
src/entity_validators.py         # Entity grounding validation
src/nli_answer_evidence.py       # NLI answer-evidence scoring
scripts/calibrate_fhri.py        # Logistic regression calibration
```

### **Enhanced File**
```
src/fhri_scoring.py  # Fact-based grounding (lines 253-458)
```

### **3 Documentation Files**
```
FHRI_TIGHTENING_PLAN.md     # Complete technical plan + code patches
IMPLEMENTATION_GUIDE.md      # Step-by-step integration guide
SUMMARY.md                   # High-level overview
```

---

## âš¡ Quick Commands

### Test Validators
```bash
# Numeric
python -c "from src.numeric_validators import extract_numeric_claims; print(extract_numeric_claims('AAPL \$150.50, up 5.2%'))"

# Entity
python -c "from src.entity_validators import extract_entities; print(extract_entities('Apple Inc. (AAPL) announced revenue'))"
```

### Run Evaluation
```bash
# Static mode (offline)
python scripts/evaluate_detection.py --dataset data/evaluation_dataset.json --use_static_answers --mode fhri

# Threshold sweep
python scripts/evaluate_detection.py --dataset data/evaluation_dataset.json --sweep --sweep_range "0.3,0.5,0.7,0.9"
```

### Train Calibration
```bash
python scripts/calibrate_fhri.py --dataset data/evaluation_dataset.json --output models/fhri_calibration.pkl --metric recall
```

---

## ðŸŽ¯ What's Already Integrated

âœ… **Fact-Based Grounding** in `src/fhri_scoring.py`:
- Numeric claims validated against API (5-20% tolerance)
- Entity grounding checked (tickers, companies)
- **Hard cap:** G â‰¤ 0.2 when numerics invalid
- **Aggressive downweight** for ungrounded entities

---

## ðŸ”§ What You Need to Add (4-6 hours)

Follow `IMPLEMENTATION_GUIDE.md` for detailed steps:

| Phase | File | What to Add | Lines | Time |
|-------|------|-------------|-------|------|
| **2** | `fhri_scoring.py` | N/D hard checks | ~476 | 30min |
| **3** | `fhri_scoring.py` | NLI integration | ~800 | 1hr |
| **4** | `fhri_scoring.py` | Scenario caps | ~805 | 30min |
| **5** | `fhri_scoring.py` | Entropy modulator | ~785 | 30min |
| **6** | `evaluate_detection.py` | Sweep/baselines | ~670 | 2hr |

**Total:** 4.5 hours coding + 1.5 hours testing = **6 hours**

---

## ðŸ“Š Numeric Tolerances

| Field | Tolerance | Example |
|-------|-----------|---------|
| Price | 5% | $150 Â± $7.50 |
| % Change | 10% | 5% Â± 0.5% |
| EPS | 10% | $1.50 Â± $0.15 |
| P/E | 15% | 25 Â± 3.75 |
| Revenue | 10% | $90B Â± $9B |
| Market Cap | 10% | $2T Â± $200B |

---

## ðŸŽ¨ Key Algorithms

### Grounding Penalty
```python
# If any numeric invalid â†’ G capped at 0.2
if numeric_validation["any_invalid"]:
    return 0.2

# Otherwise, apply penalty
penalty = 0.2 + (0.8 * accuracy_rate)  # 0.2-1.0
score = base_score * penalty
```

### NLI Veto
```python
# For high-risk scenarios (numeric_kpi, regulatory)
if max_contradiction >= 0.7:
    fhri = fhri * (1 - max_contradiction)  # Downscale
```

### Scenario Cap
```python
# For numeric_kpi/regulatory
if has_numeric_mismatch or not has_evidence:
    fhri = min(fhri, 0.3)  # Hard cap
```

---

## ðŸ“ˆ Expected Metrics

| Metric | Before | After |
|--------|--------|-------|
| Hallucination Recall | ~70% | **â‰¥85%** |
| Hallucination Precision | ~60% | **â‰¥75%** |
| Hallucination F1 | ~0.65 | **â‰¥0.80** |

---

## ðŸš¦ Integration Flow

```
User Query
    â†“
LLM Answer
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FHRI Scoring (src/fhri_scoring.py) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Grounding (G) - FACT-BASED âœ…       â”‚
â”‚  â€¢ Numeric validation               â”‚
â”‚  â€¢ Entity grounding                 â”‚
â”‚  â€¢ Hard cap if invalid (G â‰¤ 0.2)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Numeric/Directional (N/D) ðŸ”§        â”‚
â”‚  â€¢ Hard external checks (TODO)      â”‚
â”‚  â€¢ Only â‰¥0.8 if all valid           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NLI Answer-Evidence ðŸ”§              â”‚
â”‚  â€¢ Max contradiction (TODO)         â”‚
â”‚  â€¢ Veto if â‰¥0.7                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scenario Caps ðŸ”§                    â”‚
â”‚  â€¢ numeric_kpi: â‰¤0.3 (TODO)         â”‚
â”‚  â€¢ regulatory: â‰¤0.3 (TODO)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Entropy Modulator ðŸ”§                â”‚
â”‚  â€¢ Low G/N/D + high E â†’ Ã—0.85       â”‚
â”‚  â€¢ High G/N/D + high E â†’ Ã—0.95      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
FHRI Score (0-1)
    â†“
Threshold Check â†’ Flag if Hallucination
```

---

## ðŸ“ File Map

```
llm-fin-chatbot/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ fhri_scoring.py              â† Main scoring logic (ENHANCED âœ…)
â”‚   â”œâ”€â”€ numeric_validators.py        â† NEW âœ…
â”‚   â”œâ”€â”€ entity_validators.py         â† NEW âœ…
â”‚   â”œâ”€â”€ nli_answer_evidence.py       â† NEW âœ…
â”‚   â””â”€â”€ detectors.py                 â† NLI wrapper (existing)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ evaluate_detection.py        â† TO ENHANCE ðŸ”§
â”‚   â””â”€â”€ calibrate_fhri.py            â† NEW âœ…
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ evaluation_dataset.json      â† Labeled data (100 samples)
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ FHRI_TIGHTENING_PLAN.md      â† Technical plan âœ…
    â”œâ”€â”€ IMPLEMENTATION_GUIDE.md      â† Step-by-step âœ…
    â”œâ”€â”€ SUMMARY.md                   â† Overview âœ…
    â””â”€â”€ QUICK_REFERENCE.md           â† This file âœ…
```

---

## ðŸŽ¯ Decision Tree

**Should I cap G at 0.2?**
```
Has numeric claims?
  Yes â†’ Any invalid? (error > tolerance)
    Yes â†’ G = 0.2 âŒ
    No â†’ Apply fact penalty (0.2-1.0) âœ…
  No â†’ Check entity grounding
    All grounded â†’ No penalty âœ…
    Some ungrounded â†’ Penalty (0.3-1.0) âš ï¸
```

**Should I veto with NLI?**
```
High-risk scenario? (numeric_kpi, regulatory)
  Yes â†’ Max contradiction â‰¥ 0.7?
    Yes â†’ FHRI *= (1 - contradiction) âŒ
    No â†’ Soft penalty if â‰¥ 0.5 âš ï¸
  No â†’ Soft penalty if â‰¥ 0.5 âš ï¸
```

**Should I cap FHRI at 0.3?**
```
Scenario = numeric_kpi OR regulatory?
  Yes â†’ Has numeric mismatch OR no evidence?
    Yes â†’ FHRI = min(FHRI, 0.3) âŒ
    No â†’ No cap âœ…
  No â†’ No cap âœ…
```

---

## ðŸ§ª Test Checklist

```bash
# 1. Unit tests
python -c "from src.numeric_validators import extract_numeric_claims; assert len(extract_numeric_claims('AAPL \$150')) > 0"
python -c "from src.entity_validators import extract_entities; assert len(extract_entities('AAPL')['tickers']) > 0"

# 2. Integration test
python scripts/evaluate_detection.py --dataset data/evaluation_dataset.json --use_static_answers --mode fhri

# 3. Threshold sweep
python scripts/evaluate_detection.py --dataset data/evaluation_dataset.json --sweep --sweep_range "0.5,0.7,0.9"

# 4. Calibration
python scripts/calibrate_fhri.py --dataset data/evaluation_dataset.json --metric recall

# 5. Check results
cat results/fhri_tightened.json | grep '"hallucination_recall"'
```

---

## ðŸ”— Next Steps

1. **Read:** `IMPLEMENTATION_GUIDE.md` (30 min)
2. **Implement:** Phase 2-6 (4-6 hours)
3. **Test:** Run evaluation sweep (30 min)
4. **Calibrate:** Train model (15 min)
5. **Deploy:** A/B test (1 week monitoring)

---

## ðŸ’¡ Pro Tips

- **Start with Phase 2** (N/D hard checks) - easiest integration
- **Test incrementally** - run eval after each phase
- **Use static mode** for fast iteration (`--use_static_answers`)
- **Monitor logs** - validators log detailed debug info
- **Adjust tolerances** if needed - edit `NUMERIC_TOLERANCES` dict

---

## ðŸ†˜ Common Issues

**"Validators not available"**
â†’ Check imports in `src/fhri_scoring.py` (lines 30-43)

**"NLI detector not available"**
â†’ Run: `python -c "from src.detectors import get_nli_detector; print(get_nli_detector().is_available())"`

**"No samples for calibration"**
â†’ Run eval first: `python scripts/evaluate_detection.py --use_static_answers`

---

**Questions? â†’ See `IMPLEMENTATION_GUIDE.md` or `FHRI_TIGHTENING_PLAN.md`**
